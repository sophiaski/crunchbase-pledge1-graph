{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating graph data samples to be merged with baseline features\n",
    "\n",
    "### 1. Load in Crunchbase dataframes.\n",
    "### 2. Select date and create network dataframes.\n",
    "### 3. Save network dataframes as CSVs, and load them back in as `turicreate` SFrames.\n",
    "    Crunchbase network: files/output/network_sframes/cb/{}_df.csv\n",
    "    Pledge 1% network: files/output/network_sframes/p1/{}_df.csv\n",
    "    Model network: files/output/network_sframes/model/{}_df.csv\n",
    "    Not Pledge 1% network: files/output/network_sframes/np1/{}_df.csv\n",
    "### 4. Load SFrames into model graph and remove duplicate edges. Produce eight graphs $(2^3)$ of Crunchbase that include edges with/without weights$_1$, multiple edges$_2$, and/or two directions$_3$.\n",
    "### 5. Reduce size of Crunchbase vertices by limiting degrees of freedom from Pledge 1% companies, and save the vertices list for a few different network sizes. \n",
    "    Saved to: files/output/sample_vertices/\n",
    "### 6. Produce 100 samples of the Crunchbase graph vertices,and save to CSV. These will be merged with the baseline model features.\n",
    "    5 degrees away from Pledge 1% companies\n",
    "        Baseline: files/output/model_csvs/Model_DF_D5/B/{}.csv\n",
    "        Baseline Reduced: files/output/model_csvs/Model_DF_D5/BR/{}.csv\n",
    "        Graph & Baseline: files/output/model_csvs/Model_DF_D5/GB/{}.csv\n",
    "        Graph & Baseline Reduced: files/output/model_csvs/Model_DF_D5/GBR/{}.csv\n",
    "        Graph: files/output/model_csvs/Model_DF_D5/G/{}.csv\n",
    "    4 degrees away from Pledge 1% companies\n",
    "        Baseline: files/output/model_csvs/Model_DF_D4/B/{}.csv\n",
    "        Baseline Reduced: files/output/model_csvs/Model_DF_D4/BR/{}.csv\n",
    "        Graph & Baseline: files/output/model_csvs/Model_DF_D4/GB/{}.csv\n",
    "        Graph & Baseline Reduced: files/output/model_csvs/Model_DF_D4/GBR/{}.csv\n",
    "        Graph: files/output/model_csvs/Model_DF_D4/G/{}.csv\n",
    "\n",
    "\n",
    "## **Model**\n",
    "`p1_tag` ~ `rank` + `total_funding_usd` + `age` + `employee_count` (ordinal) + `continent` (nominal, 8 indicator columns) + `industry` (nominal, 46 indicator columns) + **ADDITIONAL GRAPH FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'graph' environment to PATH\n",
    "import sys\n",
    "sys.path.append('/home/ski/anaconda3/envs/graph/lib/python3.8/site-packages')\n",
    "\n",
    "# User defined functions\n",
    "import base_methods\n",
    "from base_methods import load_the_csvs\n",
    "import graph_methods\n",
    "from graph_methods import network_by_date, load_vertices, find_p1_affiliations, load_edges, make_graph\n",
    "import feature_methods\n",
    "from feature_methods import feature_creation, add_pagerank, add_weighted_pagerank, add_shortest_path\n",
    "from feature_methods import add_weighted_shortest_path, add_kcore, add_degree, add_triangle\n",
    "from feature_methods import update_pagerank_weight, update_pagerank_reset_prob, update_pagerank_prev_to_current\n",
    "from feature_methods import sum_weight, make_pagerank_zero, update_l1_delta, normalize_weight, pagerank_weighted\n",
    "\n",
    "# Import data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from importlib import reload\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Graph\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import turicreate\n",
    "from turicreate import pagerank, kcore, degree_counting, shortest_path, connected_components, triangle_counting\n",
    "from turicreate import SFrame, SGraph, SArray, load_sgraph, aggregate \n",
    "\n",
    "def update_cb_weights(src, edge, dst):\n",
    "    if src['__id'] != dst['__id']: # ignore self-links\n",
    "        edge['weight'] = 0\n",
    "        edge['weight_status'] = 0\n",
    "        edge['weight_type'] = 0\n",
    "        if edge['status'] == 'primary':\n",
    "            edge['weight_status'] = 3\n",
    "        if edge['status'] == 'secondary':\n",
    "            edge['weight_status'] = 2\n",
    "        if edge['status'] == 'tertiary':\n",
    "            edge['weight_status'] = 1\n",
    "        if edge['__edge_type'] == 'job':\n",
    "            edge['weight_type'] = 1\n",
    "        if edge['__edge_type'] == 'investment':\n",
    "            edge['weight_type'] = 2\n",
    "        edge['weight'] = edge['weight_status'] * edge['weight_type']\n",
    "    return (src, edge, dst)\n",
    "#cb = cb.triple_apply(update_cb_weights, ['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load in Crunchbase dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/csv/’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/model’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/np1’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/CrunchbaseGraphs/’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/sample_vertices/’: File exists\n",
      "mkdir: cannot create directory ‘/home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/’: File exists\n",
      "/HOME/SKI/DESKTOP/CRUNCHBASE-P1-MACHINE-LEARNING/FILES/OUTPUT/ORGANIZATIONS_MERGED.CSV\n",
      "ORGANIZATIONS_MERGED shape: (1131315, 18)\n",
      "ORGANIZATIONS_MERGED columns: ['uuid', 'name', 'type', 'rank', 'roles', 'country_code', 'region', 'status', 'category_groups_list', 'total_funding_usd', 'founded_on', 'closed_on', 'employee_count', 'primary_role', 'p1_tag', 'p1_date', 'age', 'continent_code']\n",
      "\n",
      "/HOME/SKI/DESKTOP/CRUNCHBASE-P1-MACHINE-LEARNING/FILES/OUTPUT/P1_JOBS.CSV\n",
      "P1_JOBS shape: (1536376, 12)\n",
      "P1_JOBS columns: ['job_uuid', 'person_uuid', 'org_uuid', 'job_type', 'person_name', 'org_name', 'title', 'is_current', 'started_on', 'ended_on', 'p1_tag', 'p1_date']\n",
      "\n",
      "/HOME/SKI/DESKTOP/CRUNCHBASE-P1-MACHINE-LEARNING/FILES/OUTPUT/P1_INVESTMENTS.CSV\n",
      "P1_INVESTMENTS shape: (517639, 17)\n",
      "P1_INVESTMENTS columns: ['investment_uuid', 'funding_round_uuid', 'investor_uuid', 'investor_name', 'investor_type', 'is_lead_investor', 'lead_investor_uuids', 'org_uuid', 'investment_type', 'announced_on', 'raised_amount_usd', 'post_money_valuation_usd', 'investor_count', 'lead_investor_count', 'org_name', 'p1_tag', 'p1_date']\n",
      "\n",
      "/HOME/SKI/DESKTOP/CRUNCHBASE-P1-MACHINE-LEARNING/FILES/OUTPUT/P1_INVESTMENTS_PARTNER.CSV\n",
      "P1_INVESTMENTS_PARTNER shape: (89926, 17)\n",
      "P1_INVESTMENTS_PARTNER columns: ['investment_uuid', 'funding_round_uuid', 'investor_uuid', 'partner_uuid', 'investor_name', 'partner_name', 'lead_investor_uuids', 'org_uuid', 'investment_type', 'announced_on', 'raised_amount_usd', 'post_money_valuation_usd', 'investor_count', 'lead_investor_count', 'org_name', 'p1_tag', 'p1_date']\n",
      "\n",
      "Pledge 1% UUID: fd9e2d10-a882-c6f4-737e-fd388d4ffd7c\n"
     ]
    }
   ],
   "source": [
    "# Store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]\n",
    "\n",
    "# Set paths to data folders\n",
    "INPUT = PWD + '/files/csv/'\n",
    "OUTPUT = PWD + '/files/output/'\n",
    "NETWORK_SFRAMES = OUTPUT + 'network_sframes/'\n",
    "CRUNCHBASE_GRAPHS = OUTPUT + 'CrunchbaseGraphs/'\n",
    "SAMPLE_VERTICES = OUTPUT + 'sample_vertices/'\n",
    "MODEL_CSVS = OUTPUT + 'model_csvs/'\n",
    "\n",
    "# Make sure those folders exist already\n",
    "!mkdir {INPUT}\n",
    "!mkdir {OUTPUT}\n",
    "!mkdir {NETWORK_SFRAMES}\n",
    "!mkdir {NETWORK_SFRAMES}p1\n",
    "!mkdir {NETWORK_SFRAMES}cb\n",
    "!mkdir {NETWORK_SFRAMES}model\n",
    "!mkdir {NETWORK_SFRAMES}np1\n",
    "!mkdir {CRUNCHBASE_GRAPHS}\n",
    "!mkdir {SAMPLE_VERTICES}\n",
    "!mkdir {MODEL_CSVS}\n",
    "\n",
    "# Create subfolders for final model_csvs -- COMMENT OUT WHEN COMPLETED\n",
    "# neighborhoods_name = ['Model_DF_D2', 'Model_DF_D3', 'Model_DF_D4', 'Model_DF_D5', 'Model_DF_ALL']\n",
    "# types = ['B', 'BR', 'G', 'GB','GBR']\n",
    "# for folder in neighborhoods_name:\n",
    "#     for subfolder in types:\n",
    "#         os.makedirs(os.path.join(MODEL_CSVS, folder, subfolder))\n",
    "\n",
    "# Load\n",
    "df,jobs,invest,invest_prtnr = load_the_csvs(loc=OUTPUT, \n",
    "                                            data=['organizations_merged','p1_jobs',\n",
    "                                                  'p1_investments','p1_investments_partner'], \n",
    "                                            verbose=True)\n",
    "\n",
    "print('Pledge 1% UUID: {}'.format(df[df['name']=='Pledge 1%'].uuid.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create mutliple merged pandaframes based on relationships using `network_by_date` function, which filters the dataframes by date to ensure the job/investment/company existed at that time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AS OF SEPTEMBER 08, 2020:\n",
      "\n",
      "CaLcUlAtInG... FORMER NEW JOB\n",
      "CaLcUlAtInG... PARTNER INVESTMENT JOB\n",
      "CaLcUlAtInG... OTHER FIRM PARTNER JOBS & INVESTMENTS FILTER\n",
      "CaLcUlAtInG... CURRENT OLD JOB FILTER\n",
      "CaLcUlAtInG... EXTRA ORGANIZATION NODES\n",
      "\n",
      "Crunchbase Neighborhood\n",
      "NODES | OUTPUT FRAME 0/CB_companies (825393, 18)\n",
      "NODES | OUTPUT FRAME 1/CB_investors (31499, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 2/CB_investments (453058, 17)\n",
      "NODES&EDGES | OUTPUT FRAME 3/CB_investment_partners (89926, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 4/CB_jobs (395270, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 5/CB_jobs_former (182483, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 6/CB_jobs_former_new (299193, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 7/CB_jobs_partner (11771, 5)\n",
      "NODES&EDGES | OUTPUT FRAME 8/CB_jobs_other_partners (351530, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 9/CB_invest_other_partners (155070, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 10/CB_jobs_current_old (66481, 12)\n",
      "NODES | OUTPUT FRAME 11/CB_extra_org_nodes (191589, 19)\n",
      "\n",
      "Pledge 1% Neighborhood\n",
      "NODES | OUTPUT FRAME 0/P1_companies (6615, 18)\n",
      "NODES | OUTPUT FRAME 1/P1_investors (141, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 2/P1_investments (12005, 17)\n",
      "NODES&EDGES | OUTPUT FRAME 3/P1_investment_partners (3628, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 4/P1_jobs (11758, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 5/P1_jobs_former (6653, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 6/P1_jobs_former_new (17224, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 7/P1_jobs_partner (1460, 5)\n",
      "NODES&EDGES | OUTPUT FRAME 8/P1_jobs_other_partners (25036, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 9/P1_invest_other_partners (33517, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 10/P1_jobs_current_old (13729, 12)\n",
      "NODES | OUTPUT FRAME 11/P1_extra_org_nodes (24993, 19)\n"
     ]
    }
   ],
   "source": [
    "date = '2020-09-08'\n",
    "cb_frames,p1_frames = network_by_date(date, df, jobs, invest, invest_prtnr, model_uuids=[], skip_not_p1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Write network dataframes to CSVs and load in as SFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save filtered dataframes as separate CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSVs\n",
    "for idx, frame in enumerate(cb_frames):\n",
    "    print(f'CB: {idx+1} OUT OF {len(cb_frames)}')\n",
    "    frame.to_csv(NETWORK_SFRAMES+'cb/{}_df.csv'.format(idx), index=False)\n",
    "for idx, frame in enumerate(p1_frames):\n",
    "    print(f'P1: {idx+1} OUT OF {len(cb_frames)}')\n",
    "    frame.to_csv(NETWORK_SFRAMES+'p1/{}_df.csv'.format(idx), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FYI: START FROM HERE IF USING THE SAME DATE AS PREVIOUS RUNS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB: 1 OUT OF 12\n",
      "CB: 2 OUT OF 12\n",
      "CB: 3 OUT OF 12\n",
      "CB: 4 OUT OF 12\n",
      "CB: 5 OUT OF 12\n",
      "CB: 6 OUT OF 12\n",
      "CB: 7 OUT OF 12\n",
      "CB: 8 OUT OF 12\n",
      "CB: 9 OUT OF 12\n",
      "CB: 10 OUT OF 12\n",
      "CB: 11 OUT OF 12\n",
      "CB: 12 OUT OF 12\n",
      "P1: 1 OUT OF 12\n",
      "P1: 2 OUT OF 12\n",
      "P1: 3 OUT OF 12\n",
      "P1: 4 OUT OF 12\n",
      "P1: 5 OUT OF 12\n",
      "P1: 6 OUT OF 12\n",
      "P1: 7 OUT OF 12\n",
      "P1: 8 OUT OF 12\n",
      "P1: 9 OUT OF 12\n",
      "P1: 10 OUT OF 12\n",
      "P1: 11 OUT OF 12\n",
      "P1: 12 OUT OF 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.273795 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.273795 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 276231 lines. Lines per second: 474273</pre>"
      ],
      "text/plain": [
       "Read 276231 lines. Lines per second: 474273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 825393 lines in 1.75292 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 825393 lines in 1.75292 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.031962 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.031962 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 31499 lines in 0.039823 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 31499 lines in 0.039823 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.206311 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.206311 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 453058 lines in 0.747917 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 453058 lines in 0.747917 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.121914 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.121914 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 89926 lines in 0.185685 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 89926 lines in 0.185685 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.222442 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.222442 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 395270 lines in 0.557178 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 395270 lines in 0.557178 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.159907 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.159907 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 182483 lines in 0.256003 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 182483 lines in 0.256003 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.222942 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.222942 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 278964 lines. Lines per second: 802813</pre>"
      ],
      "text/plain": [
       "Read 278964 lines. Lines per second: 802813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 299193 lines in 0.406221 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 299193 lines in 0.406221 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.007657 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.007657 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 11771 lines in 0.009339 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 11771 lines in 0.009339 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.224819 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.224819 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 351530 lines in 0.482621 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 351530 lines in 0.482621 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.187253 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.187253 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str,float,float,str,int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 155070 lines in 0.328892 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 155070 lines in 0.328892 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.057748 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.057748 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 66481 lines in 0.094342 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 66481 lines in 0.094342 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.194875 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.194875 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 191589 lines in 0.353337 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 191589 lines in 0.353337 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.008959 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.008959 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 6615 lines in 0.009053 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 6615 lines in 0.009053 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.002788 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.002788 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 141 lines in 0.002657 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 141 lines in 0.002657 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.01711 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.01711 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 12005 lines in 0.017569 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 12005 lines in 0.017569 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.008566 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.008566 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 3628 lines in 0.008438 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 3628 lines in 0.008438 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.012796 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.012796 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 11758 lines in 0.017651 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 11758 lines in 0.017651 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.009118 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.009118 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 6653 lines in 0.00915 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 6653 lines in 0.00915 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.016912 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.016912 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 17224 lines in 0.025412 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 17224 lines in 0.025412 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.00428 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.00428 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1460 lines in 0.002778 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1460 lines in 0.002778 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.023313 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.023313 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 25036 lines in 0.035337 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 25036 lines in 0.035337 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.050708 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.050708 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 33517 lines in 0.091772 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 33517 lines in 0.091772 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.014513 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.014513 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 13729 lines in 0.020302 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 13729 lines in 0.020302 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.030236 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.030236 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 24993 lines in 0.039242 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 24993 lines in 0.039242 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading SFrames\n",
    "lst_of_frames = []\n",
    "for val in ['cb','p1']:\n",
    "    lst = []\n",
    "    for idx in range(12):\n",
    "        lst.append(SFrame(data=NETWORK_SFRAMES+'{}/{}_df.csv'.format(val, idx)))\n",
    "    lst_of_frames.append(lst)\n",
    "cb_sframes,p1_sframes = lst_of_frames\n",
    "\n",
    "# List of Pledge 1% uuids for sampling\n",
    "p1_companies_uuid = []\n",
    "p1_companies_uuid.extend(list(p1_sframes[0]['uuid'].unique()))\n",
    "p1_companies_uuid.extend(list(p1_sframes[1]['uuid'].unique()))\n",
    "p1_companies_uuid = list(set(p1_companies_uuid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load SFrames into graph and remove duplicate edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use functions to load in formatted SFrames into SGraph, `load_vertices`, `p1_affiliations`, and `load_edges` which feed into `make_graphs` user-defined methods. Then, remove duplicate edges.\n",
    "\n",
    "#### Nodes: Person, Company, or Investor\n",
    "\n",
    "    Node attributes: `__id`, `__node_type`, `name`, `p1_tag`\n",
    "\n",
    "#### Edges: Investment, Job\n",
    "\n",
    "    Edge attributes: `__src_id`, `__dst_id`, `__edge_type`, `status`, {`__id`}, {`investment_type`, `raised_amount_usd`, `investor_count`, `is_lead_investor`, `lead_investor_count`}, {`job_type`, `title`}\n",
    "\n",
    "Reference: <a href='https://github.com/turi-code/how-to/blob/master/remove_duplicate_edges.py'>Remove duplicate edges from SGraph</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BuIlDiNg GrApH...\n",
      "\n",
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 2,094,708 --> 1,948,405\n",
      "\n",
      "PRIMARY Edge change: 938,254 --> 938,244\n",
      "SECONDARY Edge change: 649,854 --> 572,265\n",
      "TERTIARY Edge change: 506,600 --> 437,896\n",
      "\n",
      "SAVING Cruncbase_1Way_MultiEdge: (1290346,1948405)\n",
      "**************************************************\n",
      "\n",
      "BuIlDiNg GrApH...\n",
      "- REMOVING PARALLEL EDGES\n",
      "\n",
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 2,094,708 --> 981,877\n",
      "\n",
      "PRIMARY Edge change: 938,254 --> 526,953\n",
      "SECONDARY Edge change: 649,854 --> 306,231\n",
      "TERTIARY Edge change: 506,600 --> 148,693\n",
      "\n",
      "SAVING Cruncbase_1Way_SingleEdge: (1290346,981877)\n",
      "**************************************************\n",
      "\n",
      "BuIlDiNg GrApH...\n",
      "- ADDING EDGES IN THE REVERSE DIRECTION\n",
      "\n",
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 4,189,416 --> 3,896,556\n",
      "\n",
      "PRIMARY Edge change: 1,876,508 --> 1,876,400\n",
      "SECONDARY Edge change: 1,299,708 --> 1,144,364\n",
      "TERTIARY Edge change: 1,013,200 --> 875,792\n",
      "\n",
      "SAVING Crunchbase_2Ways_MultiEdge: (1290346,3896556)\n",
      "**************************************************\n",
      "\n",
      "BuIlDiNg GrApH...\n",
      "- ADDING EDGES IN THE REVERSE DIRECTION\n",
      "- REMOVING PARALLEL EDGES\n",
      "\n",
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 4,189,416 --> 1,963,489\n",
      "\n",
      "PRIMARY Edge change: 1,876,508 --> 1,053,171\n",
      "SECONDARY Edge change: 1,299,708 --> 614,784\n",
      "TERTIARY Edge change: 1,013,200 --> 295,534\n",
      "\n",
      "SAVING Crunchbase_2Ways_SingleEdge: (1290346,1963489)\n",
      "**************************************************\n",
      "\n",
      "BuIlDiNg GrApH...\n",
      "- ADDING WEIGHTS IN THE FORWARD DIRECTION\n",
      "\n",
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 2,094,708 --> 1,948,405\n",
      "\n",
      "PRIMARY Edge change: 938,254 --> 938,244\n",
      "SECONDARY Edge change: 649,854 --> 572,265\n",
      "TERTIARY Edge change: 506,600 --> 437,896\n",
      "\n",
      "SAVING Cruncbase_1Way_MultiEdge_Weighted: (1290346,1948405)\n",
      "**************************************************\n",
      "\n",
      "BuIlDiNg GrApH...\n",
      "- ADDING WEIGHTS IN THE FORWARD DIRECTION\n",
      "- REMOVING PARALLEL EDGES\n",
      "\n",
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 2,094,708 --> 1,746,495\n",
      "\n",
      "PRIMARY Edge change: 938,254 --> 803,256\n",
      "SECONDARY Edge change: 649,854 --> 536,454\n",
      "TERTIARY Edge change: 506,600 --> 406,785\n",
      "\n",
      "SAVING Cruncbase_1Way_SingleEdge_Weighted: (1290346,1746495)\n",
      "**************************************************\n",
      "\n",
      "BuIlDiNg GrApH...\n",
      "- ADDING WEIGHTS IN THE FORWARD DIRECTION\n",
      "- ADDING EDGES IN THE REVERSE DIRECTION\n",
      "  - ADDING WEIGHTS IN THE REVERSE DIRECTION\n",
      "\n",
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 4,189,416 --> 3,896,556\n",
      "\n",
      "PRIMARY Edge change: 1,876,508 --> 1,876,400\n",
      "SECONDARY Edge change: 1,299,708 --> 1,144,364\n",
      "TERTIARY Edge change: 1,013,200 --> 875,792\n",
      "\n",
      "SAVING Crunchbase_2Ways_MultiEdge_Weighted: (1290346,3896556)\n",
      "**************************************************\n",
      "\n",
      "BuIlDiNg GrApH...\n",
      "- ADDING WEIGHTS IN THE FORWARD DIRECTION\n",
      "- ADDING EDGES IN THE REVERSE DIRECTION\n",
      "  - ADDING WEIGHTS IN THE REVERSE DIRECTION\n",
      "- REMOVING PARALLEL EDGES\n",
      "\n",
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 4,189,416 --> 3,492,710\n",
      "\n",
      "PRIMARY Edge change: 1,876,508 --> 1,606,397\n",
      "SECONDARY Edge change: 1,299,708 --> 1,072,743\n",
      "TERTIARY Edge change: 1,013,200 --> 813,570\n",
      "\n",
      "SAVING Crunchbase_2Ways_SingleEdge_Weighted: (1290346,3492710)\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Construct all 8 graph types\n",
    "for weights_bool in [False, True]:\n",
    "    for reverse_bool in [False, True]:\n",
    "        for parallel_bool in [False, True]:\n",
    "            cb = make_graph(cb_sframes, weights=weights_bool, reverse_edges=reverse_bool, remove_parallel_edges=parallel_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading SGraphs\n",
    "- `Cruncbase_1Way_MultiEdge`: Directed SGraph, one way, parallel edges (**MAIN GRAPH**)\n",
    "\n",
    "- `Cruncbase_1Way_SingleEdge`: Directed SGraph, one way, **no parallel edges**\n",
    "\n",
    "- `Crunchbase_2Ways_MultiEdge`: Directed SGraph, **two ways**, parallel edges (**WHEN NEEDED FOR FEATURE CALCULATIONS**)\n",
    "    \n",
    "- `Crunchbase_2Ways_SingleEdge`: Directed SGraph, two ways, **no parallel edges**\n",
    "    \n",
    "There here are 4 additional graphs with weights added! See complete list in code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "cb = load_sgraph(CRUNCHBASE_GRAPHS + 'Cruncbase_1Way_MultiEdge') # SELECTED\n",
    "# cb = load_sgraph(CRUNCHBASE_GRAPHS + 'Crunchbase_2Ways_MultiEdge')\n",
    "# cb = load_sgraph(CRUNCHBASE_GRAPHS + 'Cruncbase_1Way_SingleEdge')\n",
    "# cb = load_sgraph(CRUNCHBASE_GRAPHS + 'Crunchbase_2Ways_SingleEdge')\n",
    "\n",
    "# With Weights\n",
    "# cb = load_sgraph(CRUNCHBASE_GRAPHS + 'Cruncbase_1Way_MultiEdge_Weighted')\n",
    "# cb = load_sgraph(CRUNCHBASE_GRAPHS + 'Crunchbase_2Ways_MultiEdge_Weighted')\n",
    "# cb = load_sgraph(CRUNCHBASE_GRAPHS + 'Cruncbase_1Way_SingleEdge_Weighted')\n",
    "# cb = load_sgraph(CRUNCHBASE_GRAPHS + 'Crunchbase_2Ways_SingleEdge_Weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reduce size of dataset by limiting degrees of freedom from Pledge 1% companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by getting the vertex list from the entire Crunchbase network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subgraph vertices to sample from\n",
    "cb_vertices = cb.get_vertices()\n",
    "\n",
    "# Append investors + companies together into new SFrame\n",
    "sample_vertices = cb_vertices[cb_vertices['__node_type']=='investor']\n",
    "sample_vertices = sample_vertices.append(cb_vertices[cb_vertices['__node_type']=='company'])\n",
    "\n",
    "# Save to CSV so you don't have to re-do this !\n",
    "pd.DataFrame(sample_vertices).to_csv(SAMPLE_VERTICES+'ALL_CB_Pick_Sample_Companies_From_Here.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce the CB dataset down to 5,4,3,2 degrees away from Pledge 1%, and save all as CSV.\n",
    "\n",
    "- Retrieve the graph neighborhood around a set of vertices, ignoring edge directions.\n",
    "- Reference: <a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.SGraph.get_neighborhood.html'>turicreate.SGraph.get_neighborhood</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius of the neighborhood: 2 degrees of separation from Pledge 1% companies uuids\n",
      "Reduction in nodes: 87.40%\n",
      "Reduction in edges: 61.60%\n",
      "\n",
      "Node change: 1,290,346 --> 162,579\n",
      "Edge change: 3,896,556 --> 1,496,345\n"
     ]
    }
   ],
   "source": [
    "# Define radii for calculating degrees of separation away from Pledge 1% companies\n",
    "for rad in [2,3,4,5]:\n",
    "    print(f'FOR RADIUS {rad}')\n",
    "    \n",
    "    # Create subgraph\n",
    "    cb_smol = cb.get_neighborhood(ids=p1_companies_uuid, radius=rad, full_subgraph=True)\n",
    "\n",
    "    # Save dictionaries which store info about graph\n",
    "    before = cb.summary() # Full graph\n",
    "    after = cb_smol.summary() # Subgraph\n",
    "\n",
    "    # Output\n",
    "    print('Radius of the neighborhood: {} degrees of separation from Pledge 1% companies uuids'.format(rad))\n",
    "    print('Reduction in nodes: {:.2f}%'.format((1-(after['num_vertices']/before['num_vertices']))*100))\n",
    "    print('Reduction in edges: {:.2f}%'.format((1-(after['num_edges']/before['num_edges']))*100))\n",
    "    print('\\nNode change: {:,} --> {:,}'.format(before['num_vertices'], after['num_vertices']))\n",
    "    print('Edge change: {:,} --> {:,}'.format(before['num_edges'], after['num_edges']))\n",
    "    print()\n",
    "    \n",
    "    # Get subgraph vertices to sample from\n",
    "    cb_smol_vertices = cb_smol.get_vertices()\n",
    "\n",
    "    # Append investors + companies together into new SFrame\n",
    "    sample_vertices = cb_smol_vertices[cb_smol_vertices['__node_type']=='investor']\n",
    "    sample_vertices = sample_vertices.append(cb_smol_vertices[cb_smol_vertices['__node_type']=='company'])\n",
    "\n",
    "    # Save to CSV so you don't have to re-do this !\n",
    "    pd.DataFrame(sample_vertices).to_csv(SAMPLE_VERTICES+'DEGREE_{}_Pick_Sample_Companies_From_Here.csv'.format(rad), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Produce all samples of the Crunchbase graphs. 10 for each scenario below for each neighborhood. Save to CSV.\n",
    "\n",
    "#### Neighborhoods\n",
    "- All of Crunchbase\n",
    "- 5 degrees away from Pledge 1%\n",
    "- 4 degrees away from Pledge 1%\n",
    "- 3 degrees away from Pledge 1%\n",
    "- 2 degrees away from Pledge 1%\n",
    "\n",
    "#### Scenarios $\\rightarrow$ 10 for each\n",
    "1. Baseline reduced only\n",
    "2. Baseline only\n",
    "3. Graph only\n",
    "4. Graph + Baseline reduced\n",
    "5. Graph + Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.279291 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.279291 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 276231 lines. Lines per second: 475870</pre>"
      ],
      "text/plain": [
       "Read 276231 lines. Lines per second: 475870"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 825393 lines in 1.78191 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 825393 lines in 1.78191 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.038814 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.038814 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 31499 lines in 0.057424 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 31499 lines in 0.057424 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.2161 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.2161 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 453058 lines in 0.807942 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 453058 lines in 0.807942 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.132743 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.132743 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 89926 lines in 0.216999 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 89926 lines in 0.216999 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.236056 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.236056 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 278813 lines. Lines per second: 701448</pre>"
      ],
      "text/plain": [
       "Read 278813 lines. Lines per second: 701448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 395270 lines in 0.579144 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 395270 lines in 0.579144 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.17092 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.17092 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 182483 lines in 0.28703 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 182483 lines in 0.28703 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.232503 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.232503 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 299193 lines in 0.459955 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 299193 lines in 0.459955 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.016551 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.016551 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 11771 lines in 0.018841 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 11771 lines in 0.018841 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.236076 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.236076 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 351530 lines in 0.520779 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 351530 lines in 0.520779 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.196208 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.196208 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str,float,float,str,int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 155070 lines in 0.349304 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 155070 lines in 0.349304 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.066835 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.066835 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 66481 lines in 0.10254 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 66481 lines in 0.10254 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.203351 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.203351 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/cb/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 191589 lines in 0.359667 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 191589 lines in 0.359667 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.0185 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.0185 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 6615 lines in 0.018301 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 6615 lines in 0.018301 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.012297 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.012297 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 141 lines in 0.011926 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 141 lines in 0.011926 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.024177 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.024177 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 12005 lines in 0.027933 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 12005 lines in 0.027933 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.017671 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.017671 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 3628 lines in 0.018069 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 3628 lines in 0.018069 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.024365 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.024365 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 11758 lines in 0.028175 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 11758 lines in 0.028175 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.018427 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.018427 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 6653 lines in 0.017659 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 6653 lines in 0.017659 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.026527 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.026527 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 17224 lines in 0.033213 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 17224 lines in 0.033213 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.013542 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.013542 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1460 lines in 0.011852 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1460 lines in 0.011852 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.032565 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.032565 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 25036 lines in 0.044953 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 25036 lines in 0.044953 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.058503 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.058503 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,float,float,float,str,int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 33517 lines in 0.080952 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 33517 lines in 0.080952 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.023314 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.023314 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 13729 lines in 0.028583 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 13729 lines in 0.028583 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.038675 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.038675 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,float,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/network_sframes/p1/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 24993 lines in 0.045723 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 24993 lines in 0.045723 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading SFrames\n",
    "lst_of_frames = []\n",
    "for val in ['cb','p1']:\n",
    "    lst = []\n",
    "    for idx in range(12):\n",
    "        lst.append(SFrame(data=NETWORK_SFRAMES+'{}/{}_df.csv'.format(val, idx)))\n",
    "    lst_of_frames.append(lst)\n",
    "cb_sframes,p1_sframes = lst_of_frames\n",
    "\n",
    "# List of Pledge 1% uuids\n",
    "p1_companies_uuid = list(p1_sframes[0]['uuid'].unique())\n",
    "p1_companies_uuid.extend(list(p1_sframes[1]['uuid'].unique()))\n",
    "p1_companies_uuid = list(set(p1_companies_uuid))\n",
    "positive_labels = p1_companies_uuid\n",
    "\n",
    "# Load CB Graphs\n",
    "cb0 = load_sgraph(CRUNCHBASE_GRAPHS+'Cruncbase_1Way_MultiEdge')\n",
    "cb1 = load_sgraph(CRUNCHBASE_GRAPHS+'Crunchbase_2Ways_MultiEdge')\n",
    "cb2 = load_sgraph(CRUNCHBASE_GRAPHS+'Cruncbase_1Way_SingleEdge')\n",
    "cb3 = load_sgraph(CRUNCHBASE_GRAPHS+'Crunchbase_2Ways_SingleEdge')\n",
    "\n",
    "# Load CB Graphs With Weights\n",
    "cb0w = load_sgraph(CRUNCHBASE_GRAPHS+'Cruncbase_1Way_MultiEdge_Weighted')\n",
    "cb1w = load_sgraph(CRUNCHBASE_GRAPHS+'Crunchbase_2Ways_MultiEdge_Weighted')\n",
    "cb2w = load_sgraph(CRUNCHBASE_GRAPHS+'Cruncbase_1Way_SingleEdge_Weighted')\n",
    "cb3w = load_sgraph(CRUNCHBASE_GRAPHS+'Crunchbase_2Ways_SingleEdge_Weighted')\n",
    "\n",
    "# Dataframe vertices from different Crunchbase graphs\n",
    "ALL_vertices = pd.read_csv(SAMPLE_VERTICES+'ALL_CB_Pick_Sample_Companies_From_Here.csv')\n",
    "DEGREE_5_vertices = pd.read_csv(SAMPLE_VERTICES+'/DEGREE_5_Pick_Sample_Companies_From_Here.csv')\n",
    "DEGREE_4_vertices = pd.read_csv(SAMPLE_VERTICES+'DEGREE_4_Pick_Sample_Companies_From_Here.csv')\n",
    "DEGREE_4_vertices = pd.read_csv(SAMPLE_VERTICES+'DEGREE_4_Pick_Sample_Companies_From_Here.csv')\n",
    "DEGREE_3_vertices = pd.read_csv(SAMPLE_VERTICES+'DEGREE_3_Pick_Sample_Companies_From_Here.csv')\n",
    "DEGREE_2_vertices = pd.read_csv(SAMPLE_VERTICES+'DEGREE_2_Pick_Sample_Companies_From_Here.csv')\n",
    "\n",
    "# Setting up loops\n",
    "neighborhoods_name = ['Model_DF_D2', 'Model_DF_D3', 'Model_DF_D4', 'Model_DF_D5', 'Model_DF_ALL']\n",
    "neighborhoods = [DEGREE_2_vertices, DEGREE_3_vertices, DEGREE_4_vertices, DEGREE_5_vertices, ALL_vertices]\n",
    "neighborhoods_dict = dict(zip(neighborhoods_name,neighborhoods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create baseline scenario CSVs for each neighborhood\n",
    "\n",
    "####  The code below is for Baseline Reduced (`BR`) & Baseline (`B`) scenarios, which require no graph feature calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/B/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D2/BR/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/B/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D3/BR/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/B/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D4/BR/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/B/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_D5/BR/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/2.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/B/9.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/0.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/1.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/2.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/3.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/4.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/5.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/6.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/7.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/8.csv\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/models/Model_DF_ALL/BR/9.csv\n"
     ]
    }
   ],
   "source": [
    "for neighborhood in neighborhoods_name:\n",
    "    for scenario in ['B', 'BR']:\n",
    "        for idx in range(10):\n",
    "            \n",
    "            # Retrieve vertex dataframe\n",
    "            DF = neighborhoods_dict[neighborhood]\n",
    "            \n",
    "            # Sample equal size of non-P1 companies from vertices dataframe\n",
    "            negatives_labels = DF.sample(int(len(positive_labels)), replace=False)['__id'].to_list()\n",
    "        \n",
    "            # Combine, avoid duplicates\n",
    "            model_labels = list(np.unique(positive_labels + negatives_labels))\n",
    "            \n",
    "            # Reduce to sample CSV\n",
    "            smol_DF = DF[['__id']][DF['__id'].isin(model_labels)].reset_index(drop=True).rename({'__id':'uuid'}, axis=1)\n",
    "            \n",
    "            # Output to CSV\n",
    "            path = MODEL_CSVS+'{}/{}/{}.csv'.format(neighborhood,scenario,idx)\n",
    "            smol_DF.to_csv(path, index=False)\n",
    "            print(f'SAVING to {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for computing Graph features\n",
    "\n",
    "#### Pagerank\n",
    "- The pagerank.create() method computes the pagerank for each vertex and returns a PagerankModel. The pagerank value indicates the centrality of each node in the graph.\n",
    "- Compute the PageRank for each vertex in the graph. Return a model object with total PageRank as well as the PageRank value for each vertex in the graph.\n",
    "- Reference: <a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.pagerank.create.html#turicreate.pagerank.create'>turicreate.pagerank.create</a>\n",
    "\n",
    "#### Shortest path\n",
    "- Compute the single source shortest path distance from the source vertex to all vertices in the graph. Note that because SGraph is directed, shortest paths are also directed. To find undirected shortest paths add edges to the SGraph in both directions. Return a model object with distance each of vertex in the graph.\n",
    "- Reference: <a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.shortest_path.create.html#turicreate.shortest_path.create'>turicreate.shortest_path.create</a>\n",
    "\n",
    "#### K-core decomposition\n",
    "- Compute the K-core decomposition of the graph. Return a model object with total number of cores as well as the core id for each vertex in the graph.\n",
    "- Reference: <a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.kcore.create.html'>turicreate.kcore.create</a>\n",
    "\n",
    "#### Degree counting\n",
    "- Compute the in degree, out degree and total degree of each vertex.\n",
    "- Reference: <a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.degree_counting.create.html#turicreate.degree_counting.create'>turicreate.degree_counting.create</a>\n",
    "\n",
    "#### Triangle Counting\n",
    "- Compute the number of triangles each vertex belongs to, ignoring edge directions. A triangle is a complete subgraph with only three vertices. Return a model object with total number of triangles as well as the triangle counts for each vertex in the graph.\n",
    "- Reference: <a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.triangle_counting.create.html#turicreate.triangle_counting.create'>turicreate.triangle_counting.create</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph scenario CSVs for each neighborhood\n",
    "\n",
    "####  The code below is for Graph only (`G`), Graph & Baseline (`GB`), Graph & Baseline Reduced (`GBR`) scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model_DF_D2 | G | 1\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 307826.082546\n",
      "Iteration 1: total pagerank changed in L1 = 75742.167535\n",
      "Iteration 2: total pagerank changed in L1 = 74902.446321\n",
      "Weighted pagerank finished in: 49.795091 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 212271.521795\n",
      "Iteration 1: total pagerank changed in L1 = 9434.232451\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 80.512814 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 309730.801141\n",
      "Iteration 1: total pagerank changed in L1 = 77871.483448\n",
      "Iteration 2: total pagerank changed in L1 = 76978.687428\n",
      "Weighted pagerank finished in: 41.491970 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 216217.839974\n",
      "Iteration 1: total pagerank changed in L1 = 10348.030357\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 64.592044 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10337, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/1.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | G | 2\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 307456.688482\n",
      "Iteration 1: total pagerank changed in L1 = 75672.602174\n",
      "Iteration 2: total pagerank changed in L1 = 74816.924297\n",
      "Weighted pagerank finished in: 51.526176 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 211930.884199\n",
      "Iteration 1: total pagerank changed in L1 = 9408.107535\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 83.544946 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 309342.235169\n",
      "Iteration 1: total pagerank changed in L1 = 77788.759767\n",
      "Iteration 2: total pagerank changed in L1 = 76881.103845\n",
      "Weighted pagerank finished in: 42.793586 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 215857.735464\n",
      "Iteration 1: total pagerank changed in L1 = 10318.095561\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 64.970588 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10353, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/2.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | G | 3\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 309408.230314\n",
      "Iteration 1: total pagerank changed in L1 = 77051.026059\n",
      "Iteration 2: total pagerank changed in L1 = 76190.361912\n",
      "Weighted pagerank finished in: 52.706039 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 213494.283754\n",
      "Iteration 1: total pagerank changed in L1 = 9589.482152\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 84.695655 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 311329.027595\n",
      "Iteration 1: total pagerank changed in L1 = 79199.261385\n",
      "Iteration 2: total pagerank changed in L1 = 78281.128990\n",
      "Weighted pagerank finished in: 43.955163 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 217457.287260\n",
      "Iteration 1: total pagerank changed in L1 = 10516.057066\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 66.564066 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10351, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/3.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | G | 4\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 308668.516363\n",
      "Iteration 1: total pagerank changed in L1 = 76323.912953\n",
      "Iteration 2: total pagerank changed in L1 = 75455.519508\n",
      "Weighted pagerank finished in: 53.925258 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 212821.980754\n",
      "Iteration 1: total pagerank changed in L1 = 9514.758489\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 87.508554 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 310585.479842\n",
      "Iteration 1: total pagerank changed in L1 = 78469.831748\n",
      "Iteration 2: total pagerank changed in L1 = 77540.547805\n",
      "Weighted pagerank finished in: 45.213636 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 216775.455550\n",
      "Iteration 1: total pagerank changed in L1 = 10431.754011\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 67.786341 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10329, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/4.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | G | 5\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 309411.324968\n",
      "Iteration 1: total pagerank changed in L1 = 77031.244784\n",
      "Iteration 2: total pagerank changed in L1 = 76179.514548\n",
      "Weighted pagerank finished in: 54.583385 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 213519.509439\n",
      "Iteration 1: total pagerank changed in L1 = 9600.271668\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 88.528195 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 311323.190971\n",
      "Iteration 1: total pagerank changed in L1 = 79172.848548\n",
      "Iteration 2: total pagerank changed in L1 = 78261.005968\n",
      "Weighted pagerank finished in: 45.755893 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 217470.659358\n",
      "Iteration 1: total pagerank changed in L1 = 10516.803656\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 68.255979 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10317, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/5.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | G | 6\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 310077.444807\n",
      "Iteration 1: total pagerank changed in L1 = 76715.130719\n",
      "Iteration 2: total pagerank changed in L1 = 75842.060571\n",
      "Weighted pagerank finished in: 55.520048 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 213864.328916\n",
      "Iteration 1: total pagerank changed in L1 = 9639.280473\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 88.827664 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 311978.819840\n",
      "Iteration 1: total pagerank changed in L1 = 78848.053695\n",
      "Iteration 2: total pagerank changed in L1 = 77913.625799\n",
      "Weighted pagerank finished in: 46.745062 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 217810.891161\n",
      "Iteration 1: total pagerank changed in L1 = 10570.395825\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 69.335555 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10322, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/6.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | G | 7\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 309104.805603\n",
      "Iteration 1: total pagerank changed in L1 = 76088.860319\n",
      "Iteration 2: total pagerank changed in L1 = 75246.164633\n",
      "Weighted pagerank finished in: 55.635778 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 213195.334694\n",
      "Iteration 1: total pagerank changed in L1 = 9552.365336\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 88.948240 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 310998.366174\n",
      "Iteration 1: total pagerank changed in L1 = 78219.052582\n",
      "Iteration 2: total pagerank changed in L1 = 77315.576378\n",
      "Weighted pagerank finished in: 48.032251 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 217149.956592\n",
      "Iteration 1: total pagerank changed in L1 = 10475.066262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 69.628080 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10340, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/7.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | G | 8\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 308708.591566\n",
      "Iteration 1: total pagerank changed in L1 = 76323.052097\n",
      "Iteration 2: total pagerank changed in L1 = 75485.732011\n",
      "Weighted pagerank finished in: 55.999658 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 212970.681802\n",
      "Iteration 1: total pagerank changed in L1 = 9483.691822\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 88.293785 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 310623.759951\n",
      "Iteration 1: total pagerank changed in L1 = 78464.563316\n",
      "Iteration 2: total pagerank changed in L1 = 77567.698099\n",
      "Weighted pagerank finished in: 47.424784 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 216928.960170\n",
      "Iteration 1: total pagerank changed in L1 = 10402.207028\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 71.024100 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10339, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/8.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | G | 9\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 308958.504061\n",
      "Iteration 1: total pagerank changed in L1 = 76414.680175\n",
      "Iteration 2: total pagerank changed in L1 = 75552.143462\n",
      "Weighted pagerank finished in: 57.961300 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 213202.978843\n",
      "Iteration 1: total pagerank changed in L1 = 9534.589957\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 90.621602 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 310867.992894\n",
      "Iteration 1: total pagerank changed in L1 = 78556.685053\n",
      "Iteration 2: total pagerank changed in L1 = 77635.768703\n",
      "Weighted pagerank finished in: 48.168430 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 217153.116373\n",
      "Iteration 1: total pagerank changed in L1 = 10460.556337\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 70.203334 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10382, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/G/9.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | GB | 1\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 309224.618051\n",
      "Iteration 1: total pagerank changed in L1 = 76248.547370\n",
      "Iteration 2: total pagerank changed in L1 = 75402.336381\n",
      "Weighted pagerank finished in: 58.544776 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 213226.526264\n",
      "Iteration 1: total pagerank changed in L1 = 9524.061934\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 91.150108 secs\n",
      "['__id', 'w_pr_1']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "['__id', 'spath_top_1_0', 'spath_top_1_1', 'spath_top_1_2', 'spath_top_1_3', 'spath_top_1_4', 'spath_top_min_1']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "['__id', 'w_spath_top_1_0', 'w_spath_top_1_1', 'w_spath_top_1_2', 'w_spath_top_1_3', 'w_spath_top_1_4', 'w_spath_top_min_1']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_1', 'out_deg_1']\n",
      "HERE_T\n",
      "['__id']\n",
      "Creating graph CB2W\n",
      "HERE_PR\n",
      "['__id', 'pr_2']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 311129.177114\n",
      "Iteration 1: total pagerank changed in L1 = 78385.678460\n",
      "Iteration 2: total pagerank changed in L1 = 77482.325301\n",
      "Weighted pagerank finished in: 48.849643 secs\n",
      "['__id', 'w_pr_2']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id', 'kc_2']\n",
      "HERE_D\n",
      "['__id', 'in_deg_2', 'out_deg_2']\n",
      "HERE_T\n",
      "['__id', 'tri_2']\n",
      "Creating graph CB3W\n",
      "HERE_PR\n",
      "['__id', 'pr_3']\n",
      "HERE_PR_W\n",
      "Iteration 0: total pagerank changed in L1 = 217186.545968\n",
      "Iteration 1: total pagerank changed in L1 = 10448.858028\n",
      "Iteration 2: total pagerank changed in L1 = 0.000000\n",
      "Weighted pagerank finished in: 70.032046 secs\n",
      "['__id', 'w_pr_3']\n",
      "HERE_SP\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "['__id', 'spath_top_3_0', 'spath_top_3_1', 'spath_top_3_2', 'spath_top_3_3', 'spath_top_3_4', 'spath_top_min_3']\n",
      "HERE_SP_W\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "['__id', 'w_spath_top_3_0', 'w_spath_top_3_1', 'w_spath_top_3_2', 'w_spath_top_3_3', 'w_spath_top_3_4', 'w_spath_top_min_3']\n",
      "HERE_KC\n",
      "['__id', 'kc_3']\n",
      "HERE_D\n",
      "['__id', 'in_deg_3', 'out_deg_3']\n",
      "HERE_T\n",
      "['__id']\n",
      "DATAFRAME SHAPE: (10360, 45)\n",
      "SAVING to /home/ski/Desktop/crunchbase-p1-machine-learning/files/output/model_csvs/Model_DF_D2/GB/1.csv\n",
      "\n",
      "**************************************************\n",
      "Model_DF_D2 | GB | 2\n",
      "**************************************************\n",
      "Creating graph CB0W\n",
      "HERE_PR\n",
      "['__id', 'pr_0']\n",
      "HERE_PR_W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: total pagerank changed in L1 = 308761.759348\n",
      "Iteration 1: total pagerank changed in L1 = 76692.924504\n",
      "Iteration 2: total pagerank changed in L1 = 75847.950882\n",
      "Weighted pagerank finished in: 57.735590 secs\n",
      "['__id', 'w_pr_0']\n",
      "HERE_SP\n",
      "['__id']\n",
      "HERE_SP_W\n",
      "['__id']\n",
      "HERE_KC\n",
      "['__id']\n",
      "HERE_D\n",
      "['__id', 'in_deg_0', 'out_deg_0']\n",
      "HERE_T\n",
      "['__id', 'tri_0']\n",
      "Creating graph CB1W\n",
      "HERE_PR\n",
      "['__id', 'pr_1']\n",
      "HERE_PR_W\n"
     ]
    }
   ],
   "source": [
    "# Turicreate\n",
    "turicreate.config.set_runtime_config('TURI_DEFAULT_NUM_GRAPH_LAMBDA_WORKERS', 96)\n",
    "\n",
    "# Fields needed\n",
    "sgraph_idx = {0:'cb0w',1:'cb1w',2:'cb2w', 3:'cb3w'} # Only needed weighted versions\n",
    "sgraph_idx_inv = {v:k for (k,v) in sgraph_idx.items()} # For saving the right column name\n",
    "\n",
    "# List of graphs used in loop\n",
    "list_of_graphs = [cb0w,cb1w,cb2w,cb3w]\n",
    "\n",
    "# Coordinating -- for loading in graphs\n",
    "feat_graph_map = {'pagerank':['cb0w', 'cb1w', 'cb2w', 'cb3w'],\n",
    "                  'pagerank_weight':['cb0w', 'cb1w', 'cb2w', 'cb3w'],\n",
    "                  'kcore':['cb2w', 'cb3w'], # Number of edges does not matter, single edge\n",
    "                  'degree':['cb0w', 'cb1w', 'cb2w', 'cb3w'], # Doesn't require a lot of computational power\n",
    "                  'triangle':['cb0w', 'cb2w'], # Ignores edge directions, 1-way\n",
    "                  'shortest':['cb1w', 'cb3w'],  # Requires bi-directional edges\n",
    "                  'shortest_weight':['cb1w', 'cb3w']} # Requires bi-directional edges\n",
    "\n",
    "for neighborhood in neighborhoods_name: # 2 times\n",
    "    for scenario in ['G','GB','GBR']: # 3 times\n",
    "        for idx in range(1,10): # 10 times\n",
    "            print('*'*50)\n",
    "            print('{} | {} | {}'.format(neighborhood,scenario,idx))\n",
    "            print('*'*50)\n",
    "            # Grab neighborhood DF to start with\n",
    "            DF = neighborhoods_dict[neighborhood]\n",
    "            # Sample equal size of non-P1 companies from vertices dataframe\n",
    "            negatives_labels = DF.sample(int(len(positive_labels)), replace=False)['__id'].to_list()\n",
    "            # Combine, avoid duplicates\n",
    "            model_labels = list(np.unique(positive_labels + negatives_labels))\n",
    "            # SEND TO GRAPH FEATURE METHOD WHICH: CREATES GRAPH FOR FEATURE & APPENDS FEATURE TO MODEL DATAFRAME\n",
    "            smol_DF = feature_creation(model_labels, list_of_graphs, p1_companies_uuid)\n",
    "            # Output to CSV\n",
    "            path = MODEL_CSVS+'{}/{}/{}.csv'.format(neighborhood,scenario,idx)\n",
    "            smol_DF.to_csv(path, index=False)\n",
    "            print('SAVING to {}\\n'.format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FYI: Old code from previous graph feature testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fields needed for this function\n",
    "# lst_of_graphs = [cb0,cb1,cb2,cb3,cb0w,cb1w,cb2w,cb3w]\n",
    "# sgraph_idx_assign = {0:'cb0',1:'cb1',2:'cb2',3:'cb3',0:'cb0',1:'cb1',2:'cb2',3:'cb3'}\n",
    "# vertex_type_list = ['cb_smol_ALL', 'cb_smol_D5', 'cb_smol_D4', 'cb_smol_D3', 'cb_smol_D2']\n",
    "# model_uuids_dict = {v:[] for v in vertex_type_list}\n",
    "\n",
    "# def make_smol_sgraphs(positive_labels, vertex_df, string, SGraph_list, radius=3):\n",
    "    \n",
    "#     # Sample equal size of non-P1 companies from vertices dataframe\n",
    "#     negatives_labels = vertex_df.sample(int(len(positive_labels)), replace=False)['__id'].to_list()\n",
    "        \n",
    "#     # Combine, avoid duplicates\n",
    "#     model_labels = list(np.unique(positive_labels + negatives_labels))\n",
    "\n",
    "#     for idx,graph in enumerate(SGraph_list):\n",
    "            \n",
    "#         # Create subgraph\n",
    "#         print('Creating graph {}'.format(sgraph_idx_assign[idx].upper()))\n",
    "#         smol = graph.get_neighborhood(ids=model_labels, radius=radius, full_subgraph=True)   \n",
    "            \n",
    "#         # Save subgraph\n",
    "#         path = 'ModelGraphs/test/{}_{}'.format(string,sgraph_idx_assign[idx])\n",
    "#         smol.save(path)\n",
    "#         print('SAVING to {}\\n'.format(path))\n",
    "        \n",
    "#     # Output model labels for this set of graphs\n",
    "#     return model_labels\n",
    "\n",
    "# model_labels = make_smol_sgraphs(positive_labels, ALL_vertices, 'cb_smol_ALL', lst_of_graphs, radius=3)\n",
    "# model_uuids_dict['cb_smol_ALL'] = model_labels\n",
    "\n",
    "# model_labels = make_smol_sgraphs(positive_labels, DEGREE_5_vertices, 'cb_smol_D5',lst_of_graphs, radius=3)\n",
    "# model_uuids_dict['cb_smol_D5'] = model_labels\n",
    "\n",
    "# model_labels = make_smol_sgraphs(positive_labels, DEGREE_4_vertices, 'cb_smol_D4',lst_of_graphs, radius=3)\n",
    "# model_uuids_dict['cb_smol_D4'] = model_labels\n",
    "\n",
    "# model_labels = make_smol_sgraphs(positive_labels, DEGREE_3_vertices, 'cb_smol_D3',lst_of_graphs, radius=3)\n",
    "# model_uuids_dict['cb_smol_D3'] = model_labels\n",
    "\n",
    "# model_labels = make_smol_sgraphs(positive_labels, DEGREE_2_vertices, 'cb_smol_D2', lst_of_graphs, radius=3)\n",
    "# model_uuids_dict['cb_smol_D2'] = model_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaLcUlAtInG pAgeRaNk for graph CB0, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG pAgeRaNk for graph CB1, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG pAgeRaNk for graph CB2, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG pAgeRaNk for graph CB3, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG pAgeRaNk for graph CB0, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG pAgeRaNk for graph CB1, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG pAgeRaNk for graph CB2, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG pAgeRaNk for graph CB3, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG pAgeRaNk for graph CB0, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG pAgeRaNk for graph CB1, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG pAgeRaNk for graph CB2, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG pAgeRaNk for graph CB3, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG kCoRe for graph CB0, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG kCoRe for graph CB1, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG kCoRe for graph CB2, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG kCoRe for graph CB3, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG kCoRe for graph CB0, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG kCoRe for graph CB1, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG kCoRe for graph CB2, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG kCoRe for graph CB3, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG kCoRe for graph CB0, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG kCoRe for graph CB1, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG kCoRe for graph CB2, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG kCoRe for graph CB3, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG dEgReEs for graph CB0, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG dEgReEs for graph CB1, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG dEgReEs for graph CB0, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG dEgReEs for graph CB1, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG dEgReEs for graph CB0, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG dEgReEs for graph CB1, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG TrIaNgLeS for graph CB0, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG TrIaNgLeS for graph CB1, in graph neighborhood CB_SMOL_ALL\n",
      "CaLcUlAtInG TrIaNgLeS for graph CB0, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG TrIaNgLeS for graph CB1, in graph neighborhood CB_SMOL_D4\n",
      "CaLcUlAtInG TrIaNgLeS for graph CB0, in graph neighborhood CB_SMOL_D2\n",
      "CaLcUlAtInG TrIaNgLeS for graph CB1, in graph neighborhood CB_SMOL_D2\n"
     ]
    }
   ],
   "source": [
    "# # Coordinating -- for loading in graphs\n",
    "# vertex_type_list = ['cb_smol_ALL', 'cb_smol_D4','cb_smol_D2']\n",
    "# feat_graph_map = {'pagerank':['cb0','cb1','cb2','cb3'], \n",
    "#                   'kcore':['cb0','cb1','cb2','cb3'],\n",
    "#                   'degree':['cb0','cb1'], \n",
    "#                   'triangle':['cb0','cb1'],\n",
    "#                   'shortest':['cb1', 'cb3'], \n",
    "#                   'shortest_weight':['cb1w', 'cb3w']}\n",
    "# vertex_df_map = {v:pd.DataFrame(columns=['__id']) for v in vertex_type_list}\n",
    "\n",
    "# from turicreate import pagerank\n",
    "# from functools import reduce\n",
    "\n",
    "# # Mapping for this function\n",
    "# sgraph_idx_assign = {0:'cb0',1:'cb1',2:'cb2',3:'cb3'}\n",
    "\n",
    "# if not len(sgraph_idx_assign.items())==len(feat_graph_map['pagerank']):\n",
    "#     print('THE ASSIGNMENT DOES NOT MATCH NUMBER OF GRAPHS')\n",
    "\n",
    "# for vertex_type in vertex_type_list:\n",
    "#     lst_of_frames = []\n",
    "#     for idx,smol in enumerate(feat_graph_map['pagerank']):\n",
    "#         print('CaLcUlAtInG pAgeRaNk for graph {}, in graph neighborhood {}'.format(sgraph_idx_assign[idx].upper(),vertex_type.upper()))\n",
    "#         path = 'ModelGraphs/test/{}_{}'.format(vertex_type,smol)\n",
    "#         graph = load_sgraph(path)\n",
    "#         pr = pagerank.create(graph, verbose=False)\n",
    "#         pr_sframe = pr['pagerank']\n",
    "\n",
    "#         # Modifying output SFrame\n",
    "#         pr_df = pd.DataFrame(pr_sframe)\n",
    "#         pr_df = pr_df.drop('delta', axis=1)\n",
    "#         pr_df = pr_df[pr_df['__id'].isin(model_uuids_dict[vertex_type])].reset_index(drop=True)\n",
    "#         pr_df = pr_df.rename({'pagerank':'pr_{}'.format(idx)}, axis=1)\n",
    "        \n",
    "#         # Save to temp lst_of_frames\n",
    "#         lst_of_frames.append(pr_df)\n",
    "    \n",
    "#     PR_DF = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_frames)\n",
    "#     vertex_df_map[vertex_type] = pd.merge(vertex_df_map[vertex_type], PR_DF, on='__id', how='outer')\n",
    "    \n",
    "#################################################################################\n",
    "# from turicreate import kcore\n",
    "# # Mapping for this function\n",
    "# sgraph_idx_assign = {0:'cb0',1:'cb1',2:'cb2',3:'cb3'}\n",
    "\n",
    "# if not len(sgraph_idx_assign.items())==len(feat_graph_map['kcore']):\n",
    "#     print('THE ASSIGNMENT DOES NOT MATCH NUMBER OF GRAPHS')\n",
    "\n",
    "# for vertex_type in vertex_type_list:\n",
    "#     lst_of_frames = []\n",
    "#     for idx,smol in enumerate(feat_graph_map['kcore']):\n",
    "#         print('CaLcUlAtInG kCoRe for graph {}, in graph neighborhood {}'.format(sgraph_idx_assign[idx].upper(),vertex_type.upper()))\n",
    "#         path = 'ModelGraphs/test/{}_{}'.format(vertex_type, smol)\n",
    "#         graph = load_sgraph(path)\n",
    "#         kc = kcore.create(graph, kmin=0, kmax=10, verbose=False)\n",
    "#         kc_sframe = kc['core_id'] \n",
    "        \n",
    "#         # Modifying output SFrame\n",
    "#         kc_df = pd.DataFrame(kc_sframe)\n",
    "#         kc_df = kc_df[kc_df['__id'].isin(model_uuids_dict[vertex_type])].reset_index(drop=True)\n",
    "#         kc_df = kc_df.rename({'core_id':'kc_{}'.format(idx)}, axis=1)\n",
    "        \n",
    "#         # Save to temp lst_of_frames\n",
    "#         lst_of_frames.append(kc_df)\n",
    "    \n",
    "#     KC_DF = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_frames)\n",
    "#     vertex_df_map[vertex_type] = pd.merge(vertex_df_map[vertex_type], KC_DF, on='__id', how='outer')\n",
    "\n",
    "#################################################################################\n",
    "# from turicreate import degree_counting\n",
    "# # Mapping for this function\n",
    "# sgraph_idx_assign = {0:'cb0',1:'cb1'}\n",
    "\n",
    "# if not len(sgraph_idx_assign.items())==len(feat_graph_map['degree']):\n",
    "#     print('THE ASSIGNMENT DOES NOT MATCH NUMBER OF GRAPHS')\n",
    "\n",
    "# for vertex_type in vertex_type_list:\n",
    "#     lst_of_frames = []\n",
    "#     for idx,smol in enumerate(feat_graph_map['degree']):\n",
    "#         print('CaLcUlAtInG dEgReEs for graph {}, in graph neighborhood {}'.format(sgraph_idx_assign[idx].upper(),vertex_type.upper()))\n",
    "#         path = 'ModelGraphs/test/{}_{}'.format(vertex_type, smol)\n",
    "#         graph = load_sgraph(path)\n",
    "#         deg = degree_counting.create(graph)\n",
    "#         deg_sgraph = deg['graph'] \n",
    "#         deg_df = pd.DataFrame(deg_sgraph.vertices[['__id', 'in_degree', 'out_degree']])\n",
    "#         deg_df = deg_df[deg_df['__id'].isin(model_uuids_dict[vertex_type])].reset_index(drop=True)\n",
    "#         deg_df = deg_df.rename({'in_degree':'in_deg_{}'.format(idx),\n",
    "#                              'out_degree':'out_deg_{}'.format(idx)}, axis=1)\n",
    "#         # Save to temp lst_of_frames\n",
    "#         lst_of_frames.append(deg_df)\n",
    "#     DEG_DF = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_frames)\n",
    "#     vertex_df_map[vertex_type] = pd.merge(vertex_df_map[vertex_type], DEG_DF, on='__id', how='outer')\n",
    "    \n",
    "#################################################################################\n",
    "# from turicreate import triangle_counting\n",
    "# # Mapping for this function\n",
    "# sgraph_idx_assign = {0:'cb0', 1:'cb1'}\n",
    "\n",
    "# if not len(sgraph_idx_assign.items())==len(feat_graph_map['triangle']):\n",
    "#     print('THE ASSIGNMENT DOES NOT MATCH NUMBER OF GRAPHS')\n",
    "    \n",
    "# for vertex_type in vertex_type_list:\n",
    "#     lst_of_frames = []\n",
    "#     for idx,smol in enumerate(feat_graph_map['triangle']):\n",
    "#         print('CaLcUlAtInG TrIaNgLeS for graph {}, in graph neighborhood {}'.format(sgraph_idx_assign[idx].upper(),vertex_type.upper()))\n",
    "#         path = 'ModelGraphs/test/{}_{}'.format(vertex_type, smol)\n",
    "#         graph = load_sgraph(path)\n",
    "#         tc = triangle_counting.create(graph, verbose=False)\n",
    "#         tri_df = pd.DataFrame(tc['triangle_count'])\n",
    "#         tri_df = tri_df[tri_df['__id'].isin(model_uuids_dict[vertex_type])].reset_index(drop=True)\n",
    "#         tri_df = tri_df.rename({'triangle_count':'tri_{}'.format(idx)},axis=1)\n",
    "#         # Save to temp lst_of_frames\n",
    "#         lst_of_frames.append(tri_df)\n",
    "#     TRI_DF = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_frames)\n",
    "#     vertex_df_map[vertex_type] = pd.merge(vertex_df_map[vertex_type], TRI_DF, on='__id', how='outer')\n",
    "    \n",
    "#################################################################################\n",
    "# # Mapping for this function\n",
    "# sgraph_idx_assign = {0:'cb1',1:'cb3'}\n",
    "# sgraph_idx_jdx_assign = {0:1, 1:3}\n",
    "\n",
    "# if not len(sgraph_idx_assign.items())==len(feat_graph_map['shortest']):\n",
    "#     print('THE ASSIGNMENT DOES NOT MATCH NUMBER OF GRAPHS')\n",
    "    \n",
    "# for vertex_type in vertex_type_list:\n",
    "#     lst_of_frames = []\n",
    "\n",
    "#     for idx,smol in enumerate(feat_graph_map['shortest']):\n",
    "#         print('CaLcUlAtInG sHoRtEsT PaTh tOP P1 for graph {}, in graph neighborhood {}'.format(sgraph_idx_assign[idx].upper(),vertex_type.upper()))\n",
    "#         path = 'ModelGraphs/test/{}_{}'.format(vertex_type, smol)\n",
    "#         graph = load_sgraph(path)\n",
    "#         pr = vertex_df_map[vertex_type][['__id', 'pr_{}'.format(sgraph_idx_jdx_assign[idx])]].sort_values(by='pr_{}'.format(sgraph_idx_jdx_assign[idx]),ascending=False)\n",
    "#         pr = pr['__id'].to_list()[:200]\n",
    "#         count = 0\n",
    "#         top_p1 = []\n",
    "#         while len(top_p1) < 5:\n",
    "#             if pr[count] in p1_companies_uuid:\n",
    "#                 top_p1.append(pr[count])\n",
    "#             count += 1\n",
    "#         lst_of_lst_of_frames = []\n",
    "#         for jdx,uuid in enumerate(top_p1):\n",
    "#             sp = shortest_path.create(graph, source_vid=uuid, verbose=False)\n",
    "#             sp_df = pd.DataFrame(sp['distance'])\n",
    "#             sp_df = sp_df[sp_df['__id'].isin(model_uuids_dict[vertex_type])].reset_index(drop=True)\n",
    "#             sp_df = sp_df.rename({'distance': 'spath_top_{}_{}'.format(sgraph_idx_jdx_assign[idx],jdx)}, axis=1)\n",
    "#             lst_of_lst_of_frames.append(sp_df)\n",
    "#         sp_df = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_lst_of_frames)\n",
    "#         sp_df['spath_top_min_{}'.format(sgraph_idx_jdx_assign[idx])] = sp_df.min(axis=1) \n",
    "#         lst_of_frames.append(sp_df)\n",
    "\n",
    "#     DIST_DF = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_frames)\n",
    "#     vertex_df_map[vertex_type] = pd.merge(vertex_df_map[vertex_type], DIST_DF, on='__id', how='outer')\n",
    "    \n",
    "#################################################################################\n",
    "# from turicreate import shortest_path\n",
    "\n",
    "# # Mapping for this function\n",
    "# sgraph_idx_assign = {0:'cb1w',1:'cb3w'}\n",
    "# sgraph_idx_jdx_assign = {0:1, 1:3}\n",
    "\n",
    "# if not len(sgraph_idx_assign.items())==len(feat_graph_map['shortest']):\n",
    "#     print('THE ASSIGNMENT DOES NOT MATCH NUMBER OF GRAPHS')\n",
    "    \n",
    "# for vertex_type in vertex_type_list:\n",
    "#     lst_of_frames = []\n",
    "\n",
    "#     for idx,smol in enumerate(feat_graph_map['shortest_weight']):\n",
    "#         print('CaLcUlAtInG sHoRtEsT PaTh tOP P1 for graph {}, in graph neighborhood {}'.format(sgraph_idx_assign[idx].upper(),vertex_type.upper()))\n",
    "#         path = 'ModelGraphs/test/{}_{}'.format(vertex_type, smol)\n",
    "#         graph = load_sgraph(path)\n",
    "#         pr = vertex_df_map[vertex_type][['__id', 'pr_{}'.format(sgraph_idx_jdx_assign[idx])]].sort_values(by='pr_{}'.format(sgraph_idx_jdx_assign[idx]),ascending=False)\n",
    "#         pr = pr['__id'].to_list()[:200]\n",
    "#         count = 0\n",
    "#         top_p1 = []\n",
    "#         while len(top_p1) < 5:\n",
    "#             if pr[count] in p1_companies_uuid:\n",
    "#                 top_p1.append(pr[count])\n",
    "#             count += 1\n",
    "#         lst_of_lst_of_frames = []\n",
    "#         for jdx,uuid in enumerate(top_p1):\n",
    "#             sp = shortest_path.create(graph, source_vid=uuid, weight_field='weight', verbose=False)\n",
    "#             sp_df = pd.DataFrame(sp['distance'])\n",
    "#             sp_df = sp_df[sp_df['__id'].isin(model_uuids_dict[vertex_type])].reset_index(drop=True)\n",
    "#             sp_df = sp_df.rename({'distance': 'w_spath_top_{}_{}'.format(sgraph_idx_jdx_assign[idx],jdx)}, axis=1)\n",
    "#             lst_of_lst_of_frames.append(sp_df)\n",
    "#         sp_df = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_lst_of_frames)\n",
    "#         sp_df['w_spath_top_min_{}'.format(sgraph_idx_jdx_assign[idx])] = sp_df.min(axis=1) \n",
    "#         lst_of_frames.append(sp_df)\n",
    "\n",
    "#     DIST_DF = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_frames)\n",
    "#     vertex_df_map[vertex_type] = pd.merge(vertex_df_map[vertex_type], DIST_DF, on='__id', how='outer')\n",
    "\n",
    "#################################################################################\n",
    "# # Weighted pagerank\n",
    "# # Mapping for this function\n",
    "# sgraph_idx_assign = {0:'cb1w',1:'cb2w', 2:'cb3w', 3:'cb4w'}\n",
    "# if not len(sgraph_idx_assign.items())==len(feat_graph_map['pagerank_weight']):\n",
    "#     print('THE ASSIGNMENT DOES NOT MATCH NUMBER OF GRAPHS')\n",
    "# for vertex_type in vertex_type_list:\n",
    "#     lst_of_frames = []\n",
    "#     for idx,smol in enumerate(feat_graph_map['pagerank_weight']):\n",
    "#         print('CaLcUlAtInG wEiGhTeD pAgeRaNk for graph {}, in graph neighborhood {}'.format(sgraph_idx_assign[idx].upper(),vertex_type.upper()))\n",
    "#         path = 'ModelGraphs/test/{}_{}'.format(vertex_type,smol)\n",
    "#         graph = load_sgraph(path)\n",
    "#         pr_w = pagerank_weighted(graph)\n",
    "#         pr_w_sframe = pr_w['__id', 'pagerank']\n",
    "#         # Modifying output SFrame\n",
    "#         pr_w_df = pd.DataFrame(pr_w_sframe)\n",
    "#         pr_w_df = pr_w_df[pr_w_df['__id'].isin(model_uuids_dict[vertex_type])].reset_index(drop=True)\n",
    "#         pr_w_df = pr_w_df.rename({'pagerank_weight':'w_pr_{}'.format(idx)}, axis=1)\n",
    "#         # Save to temp lst_of_frames\n",
    "#         lst_of_frames.append(pr_w_df)\n",
    "#     PR_W_DF = reduce(lambda df1,df2: pd.merge(df1,df2,on='__id'), lst_of_frames)\n",
    "#     vertex_df_map[vertex_type] = pd.merge(vertex_df_map[vertex_type], PR_W_DF, on='__id', how='outer')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS5sQetee7vc"
   },
   "source": [
    "# Model Pipeline\n",
    "\n",
    "By: Aditya Mengani, Ognjen Sosa, Sanjay Elangovan, Song Park, Sophia Skowronski\n",
    "\n",
    "**Can we improve on the baseline scores using different encoding, imputing, and scaling schemes?**\n",
    "- Averaged Logistic Regression accuracy Score: 0.5\n",
    "- Averaged Linear Regression accuracy score: 0.2045\n",
    "- Averaged K-Nearest Neighbour accuracy score: 0.6198\n",
    "- Averaged Naive Bayes accuracy score: 0.649\n",
    "\n",
    "**`p1_tag` ~  `rank` + `total_funding_usd` + `employee_count` (ordinal) + `country` (nominal) + `category_groups` (nominal)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lzz5DdXWTUOh"
   },
   "source": [
    "### STEPS FOR CONNECTING TO COLAB\n",
    "\n",
    "https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/\n",
    "\n",
    "*  Upload the .csv files to your google drive\n",
    "*  Go to the file in google drive, right click on file name, then click on 'Get Link' and it shows the unique id of the file. Copy it and save it in the below code:\n",
    "downloaded = drive.CreateFile({'id':\"1uWwO-geA8IRNaerjQCk92******\"}) \n",
    "*  Replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('baseline.csv')\n",
    "\n",
    "\n",
    "### Enabling GPU settings in COLAB\n",
    "\n",
    "https://www.tutorialspoint.com/google_colab/google_colab_using_free_gpu.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKGov2n9gm4i",
    "outputId": "cd1932d4-0a3a-4aef-c44f-c26bde01d4d8"
   },
   "outputs": [],
   "source": [
    "# ## GCP drive to colab connectivity Code\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "# downloaded = drive.CreateFile({'id':\"1uWwO-geA8IRNaerjQCk92KCWDlZM_6Zx\"})   # replace the id with id of file you want to access\n",
    "# downloaded.GetContentFile('baseline.csv')\n",
    "\n",
    "# downloaded = drive.CreateFile({'id':\"13zLq9t_noAl7RRsLuWmbI_fRe3rE0dpg\"})   # replace the id with id of file you want to access\n",
    "# downloaded.GetContentFile('pagerank_df_deg3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OY3uRhuhBs6",
    "outputId": "9738bc24-1302-4fa5-b342-ecbae4256890"
   },
   "outputs": [],
   "source": [
    "#pip install prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Zal_raJUhSkB"
   },
   "outputs": [],
   "source": [
    "#pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b1PxJFhiRa5c"
   },
   "outputs": [],
   "source": [
    "#pip install from libsvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8ym8TNWe7vd"
   },
   "source": [
    "## Reading in data\n",
    "\n",
    " * Read data\n",
    " * Create age feature\n",
    " * Impute the na and infinite values\n",
    " * One-hot encode countrycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Model Set up Options************************ \n",
      "Option 1 : Graph + Baseline\n",
      "Option 2 : Baseline only\n",
      "Option 3 : Graph + Baseline reduced\n",
      "Option 4 : Baseline reduced only\n",
      "Option 5 : Graph only\n",
      "*********************************************************** \n"
     ]
    }
   ],
   "source": [
    "print(\"***************Model Set up Options************************ \")\n",
    "print(\"Option 1 : Graph + Baseline\")\n",
    "print(\"Option 2 : Baseline only\")\n",
    "print(\"Option 3 : Graph + Baseline reduced\")\n",
    "print(\"Option 4 : Baseline reduced only\")\n",
    "print(\"Option 5 : Graph only\")\n",
    "print(\"*********************************************************** \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE ONLY METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Baseline_Only(df):\n",
    "    df = df.copy()\n",
    "    print(\"Original DF shape\",df.shape)\n",
    "\n",
    "    #print('\\nStarting Dataframe Columns:\\n\\n{}\\n'.format(df.columns.to_list()))\n",
    "\n",
    "    # Have industry mapper for 'ind_1'...'ind_46' columns\n",
    "    industries = ['Software', 'Information Technology', 'Internet Services', 'Data and Analytics',\n",
    "                  'Sales and Marketing', 'Media and Entertainment', 'Commerce and Shopping', \n",
    "                  'Financial Services', 'Apps', 'Mobile', 'Science and Engineering', 'Hardware',\n",
    "                  'Health Care', 'Education', 'Artificial Intelligence', 'Professional Services', \n",
    "                  'Design', 'Community and Lifestyle', 'Real Estate', 'Advertising',\n",
    "                  'Transportation', 'Consumer Electronics', 'Lending and Investments',\n",
    "                  'Sports', 'Travel and Tourism', 'Food and Beverage',\n",
    "                  'Content and Publishing', 'Consumer Goods', 'Privacy and Security',\n",
    "                  'Video', 'Payments', 'Sustainability', 'Events', 'Manufacturing',\n",
    "                  'Clothing and Apparel', 'Administrative Services', 'Music and Audio',\n",
    "                  'Messaging and Telecommunications', 'Energy', 'Platforms', 'Gaming',\n",
    "                  'Government and Military', 'Biotechnology', 'Navigation and Mapping',\n",
    "                  'Agriculture and Farming', 'Natural Resources']\n",
    "    industry_map = {industry:'ind_'+str(idx+1) for idx,industry in enumerate(industries)}\n",
    "\n",
    "    # Imputing data(TBD)\n",
    "    # Rank has na() values, imputing to zero for now\n",
    "    # total_funding_usd has na() values, imputing to zero for now\n",
    "    # Age has infinite values, imputing to zero for now\n",
    "    df['rank'] = df['rank'].fillna(0)\n",
    "    df['total_funding_usd'] = df['total_funding_usd'].fillna(0)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # No columns need to be dropped\n",
    "    df_simple = reduce_mem_usage(df)\n",
    "\n",
    "    #print('\\nEnding Dataframe Columns:\\n\\n{}'.format(df_simple.columns.to_list()))\n",
    "    print('\\nDataframe shape:', df_simple.shape)\n",
    "\n",
    "    del industries, industry_map\n",
    "    \n",
    "    return df_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE REDUCED METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELIMINIATING FEATURES: RANK and total_funding_usd (For now)\n",
    "def Baseline_Reduced(df):\n",
    "    df = df.copy()\n",
    "    print(\"Original DF shape\",df.shape)\n",
    "\n",
    "    #print('\\nStarting Dataframe Columns:\\n\\n{}\\n'.format(df.columns.to_list()))\n",
    "    # Have industry mapper for 'ind_1'...'ind_46' columns\n",
    "    industries = ['Software', 'Information Technology', 'Internet Services', 'Data and Analytics',\n",
    "                  'Sales and Marketing', 'Media and Entertainment', 'Commerce and Shopping', \n",
    "                  'Financial Services', 'Apps', 'Mobile', 'Science and Engineering', 'Hardware',\n",
    "                  'Health Care', 'Education', 'Artificial Intelligence', 'Professional Services', \n",
    "                  'Design', 'Community and Lifestyle', 'Real Estate', 'Advertising',\n",
    "                  'Transportation', 'Consumer Electronics', 'Lending and Investments',\n",
    "                  'Sports', 'Travel and Tourism', 'Food and Beverage',\n",
    "                  'Content and Publishing', 'Consumer Goods', 'Privacy and Security',\n",
    "                  'Video', 'Payments', 'Sustainability', 'Events', 'Manufacturing',\n",
    "                  'Clothing and Apparel', 'Administrative Services', 'Music and Audio',\n",
    "                  'Messaging and Telecommunications', 'Energy', 'Platforms', 'Gaming',\n",
    "                  'Government and Military', 'Biotechnology', 'Navigation and Mapping',\n",
    "                  'Agriculture and Farming', 'Natural Resources']\n",
    "    industry_map = {industry:'ind_'+str(idx+1) for idx,industry in enumerate(industries)}\n",
    "\n",
    "    # Imputing data(TBD)\n",
    "    # Rank has na() values, imputing to zero for now\n",
    "    # total_funding_usd has na() values, imputing to zero for now\n",
    "    # Age has infinite values, imputing to zero for now\n",
    "    df['rank'] = df['rank'].fillna(0)\n",
    "    df['total_funding_usd'] = df['total_funding_usd'].fillna(0)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # Reduced baseline doesnt have these two columns\n",
    "    df_simple = df.drop(['rank','total_funding_usd', 'uuid'], axis=1)\n",
    "    df_simple = reduce_mem_usage(df_simple)\n",
    "\n",
    "    #print('\\nEnding Dataframe Columns:\\n\\n{}'.format(df_simple.columns.to_list()))\n",
    "    print('\\nDataframe shape:', df_simple.shape)\n",
    "\n",
    "    del industries, industry_map\n",
    "    \n",
    "    return df_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH ONLY METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Graph_Only(df, n_degrees):\n",
    "    df = df.copy()\n",
    "    df = df[['uuid','p1_tag']]\n",
    "    df['__id'] = df['uuid']\n",
    "    print(\"Original DF shape\",df.shape)\n",
    "    \n",
    "    if n_degrees == 2:\n",
    "        df_gr = pd.read_csv('files/output/Model_DF_D2.csv',sep=',')\n",
    "        print(\"Original Model_DF_D2 shape\",df.shape)\n",
    "        #print(df_gr.columns)\n",
    "    elif n_degrees == 4:\n",
    "        df_gr = pd.read_csv('files/output/Model_DF_D4.csv',sep=',')\n",
    "        print(\"Original Model_DF_D4 shape\",df.shape)\n",
    "        #print(df_gr.columns)\n",
    "    elif n_degrees == 0:\n",
    "        df_gr = pd.read_csv('files/output/Model_DF_ALLLLL.csv',sep=',')\n",
    "        print(\"Original Model_DF_ALLLLL.csv shape\",df.shape)\n",
    "        \n",
    "    df_gr = pd.merge(df_gr.copy(),df.copy(), how = 'left',on='__id')\n",
    "    print(\"Original DF_GR shape after merge\",df_gr.shape)\n",
    "    #print(df_gr.columns)\n",
    "    df_gr = reduce_mem_usage(df_gr) \n",
    "    df_gr = df_gr.fillna(0)\n",
    "    del df\n",
    "\n",
    "    #impute\n",
    "    return df_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FOR 100 ITERATIONS\n",
    "def Graph_Only_SS(df, n_degrees, setup, iteration):\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df[['uuid','p1_tag']]\n",
    "    print(\"Original DF shape\",df.shape)\n",
    "    \n",
    "    list_Set_Up = ['BL_Only','G_Only','G+BL','G+BL_Red','BL_Red_Only']\n",
    "    folders = ['B', 'G', 'GB', 'GBR', 'BR']\n",
    "    save_map = dict(zip(list_Set_Up,folders))\n",
    "    \n",
    "    if n_degrees == 4:\n",
    "        df_gr = pd.read_csv('files/output/Model_DF_D4/{}/{}.csv'.format(save_map[setup], iteration),sep=',')\n",
    "        print(\"Original Model_DF_D2 shape\",df.shape)\n",
    "        #print(df_gr.columns)\n",
    "    elif n_degrees == 5:\n",
    "        df_gr = pd.read_csv('files/output/Model_DF_D5/{}/{}.csv'.format(save_map[setup], iteration),sep=',')\n",
    "        print(\"Original Model_DF_D4 shape\",df.shape)\n",
    "        #print(df_gr.columns)\n",
    "        \n",
    "    df_gr = pd.merge(df_gr.copy(),df.copy(),how='left',on='uuid')\n",
    "    print(\"Original DF_GR shape after merge\",df_gr.shape)\n",
    "    #print(df_gr.columns)\n",
    "    #df_gr = reduce_mem_usage(df_gr) \n",
    "    df_gr = df_gr.fillna(0)\n",
    "    del df\n",
    "\n",
    "    #impute\n",
    "    return df_gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaDSZ2aje7ve",
    "outputId": "8df246b7-5589-41ff-bb88-2b6e309e0887"
   },
   "outputs": [],
   "source": [
    "## Select equal sample of non-Pledge 1% organizations\n",
    "def gen_Train_Test_Split(df_simple):\n",
    "    df_p1 = df_simple[df_simple['p1_tag']==1]\n",
    "    print(df_p1.shape)\n",
    "    df_notp1 = df_simple[df_simple['p1_tag']==0].sample(n=df_p1.shape[0], replace=True)\n",
    "    df_model = pd.concat([df_p1, df_notp1]).reset_index(drop=True)\n",
    "    #df_model = reduce_mem_usage(df_model)\n",
    "\n",
    "    # Create variable for each feature type: categorical and numerical\n",
    "    numeric_features = df_model.select_dtypes(include=['uint8','int8', 'int16', 'int32', 'int64', 'float16', 'float32','float64']).drop(['p1_tag'], axis=1).columns\n",
    "    categorical_features = df_model.select_dtypes(include=['object']).columns\n",
    "    #print('Numeric features:', numeric_features.to_list())\n",
    "    #print('Categorical features:', categorical_features.to_list())\n",
    "\n",
    "    X = df_model.drop('p1_tag', axis=1)\n",
    "    y = df_model['p1_tag']\n",
    "    y = preprocessing.LabelEncoder().fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=99)\n",
    "    print('Training data shape:', X_train.shape)\n",
    "    print('Train label shape:', y_train.shape)\n",
    "    print('Test data shape:',  X_test.shape)\n",
    "    print('Test label shape:', y_test.shape)\n",
    "\n",
    "    # reset indexes for train and test\n",
    "    X_train= X_train.reset_index(drop=True)\n",
    "    X_test= X_test.reset_index(drop=True)\n",
    "    return X_train,X_test,X,y,y_train,y_test,numeric_features,categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORM PCA COUNTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "Hfb6xuWChK3Z",
    "outputId": "96f95c5d-8cc0-4803-86d3-2ee6a4fc88ae"
   },
   "outputs": [],
   "source": [
    "# Perform PCA of country dataset\n",
    "def PCA_Country(X_train,X_test):\n",
    "    # Perform PCA of country dataset\n",
    "    country_train = X_train.filter(regex='^country',axis=1).fillna(0)\n",
    "    country_test = X_test.filter(regex='^country',axis=1).fillna(0)\n",
    "#     # For each value of k, use PCA to project the data feature sets to k principle components\n",
    "#     matrix = [['k', 'total variance']] # For display\n",
    "#     k_values = list(range(1,113)) # To loop through, there are 112 country codes\n",
    "#     # For each value of k, use PCA to project the data feature sets to k principle components\n",
    "#     for k in k_values:\n",
    "#         pca = PCA(n_components=k, whiten=True,random_state=random.seed(1234))\n",
    "#         pca.fit(country_train)\n",
    "#         matrix.append([k, round(pca.explained_variance_ratio_.sum(),4)])\n",
    "#     # Print results\n",
    "#     print('Fraction of the total variance in the training data explained by the first k principal components:\\n')\n",
    "#     s = [[str(e) for e in row] for row in matrix]\n",
    "#     lens = [max(map(len, col)) for col in zip(*s)]\n",
    "#     fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "#     table = [fmt.format(*row) for row in s]\n",
    "#     print('\\n'.join(table))\n",
    "#     print()\n",
    "#     # Plots\n",
    "#     _, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,5))\n",
    "#     # Plotting lineplot of fraction of total variance vs. number of principal components\n",
    "#     # For all possible numbers of principal components\n",
    "#     ax.plot(np.cumsum(PCA().fit(country_train).explained_variance_ratio_))\n",
    "#     # Labels\n",
    "#     ax.set_title('Fraction of total variance vs. number of principal components')\n",
    "#     ax.set_xlabel('k = number of components')\n",
    "#     ax.set_ylabel('Cumulative explained variance')\n",
    "#     # Display\n",
    "#     plt.show()\n",
    "    \n",
    "    # create PCA features for train and test set\n",
    "    n_components = 15\n",
    "    pca = PCA(n_components=n_components,whiten=True,random_state=random.seed(1234))  \n",
    "    pca_train = pca.fit_transform(country_train)\n",
    "    pca_test = pca.transform(country_test)\n",
    "    # create dataframes from numpy\n",
    "    df_cty_train = pd.DataFrame(pca_train,columns=['cntry_pca_'+ str(x) for x in range(n_components)])\n",
    "    df_cty_test = pd.DataFrame(pca_test,columns=['cntry_pca_'+ str(x) for x in range(n_components)])\n",
    "    # drop country prefix columns\n",
    "    X_train = X_train.drop(list(X_train.filter(regex='^country_',axis=1).columns), axis=1)\n",
    "    X_test = X_test.drop(list(X_test.filter(regex='^country_',axis=1).columns), axis=1)\n",
    "    # concat with train dataset\n",
    "    X_train = pd.concat([X_train, df_cty_train],axis = 1)\n",
    "    X_test = pd.concat([X_test, df_cty_test],axis = 1)\n",
    "    del df_cty_train,df_cty_test,country_train,country_test\n",
    "    return X_train,X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORM PCA INDUSTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "hNCYcDu9gj_z",
    "outputId": "38dcead6-df46-444e-d6a4-f4a112b87ef7"
   },
   "outputs": [],
   "source": [
    "# Perform PCA of country dataset\n",
    "def PCA_Industry(X_train,X_test):\n",
    "    # Perform PCA of industry dataset\n",
    "    industry_train = X_train.filter(regex='^ind_',axis=1).fillna(0)\n",
    "    industry_test = X_test.filter(regex='^ind_',axis=1).fillna(0)\n",
    "#     # For each value of k, use PCA to project the data feature sets to k principle components\n",
    "#     matrix = [['k', 'total variance']] # For display\n",
    "#     k_values = list(range(1,47)) # To loop through, there are 46 industries\n",
    "#     # For each value of k, use PCA to project the data feature sets to k principle components\n",
    "#     for k in k_values:\n",
    "#         pca = PCA(n_components=k, whiten=True,random_state=random.seed(1234))\n",
    "#         pca.fit(industry_train)\n",
    "#         matrix.append([k, round(pca.explained_variance_ratio_.sum(),4)])\n",
    "#     # Print results\n",
    "#     print('Fraction of the total variance in the training data explained by the first k principal components:\\n')\n",
    "#     s = [[str(e) for e in row] for row in matrix]\n",
    "#     lens = [max(map(len, col)) for col in zip(*s)]\n",
    "#     fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "#     table = [fmt.format(*row) for row in s]\n",
    "#     print('\\n'.join(table))\n",
    "#     print()\n",
    "#     # Plots\n",
    "#     _, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,5))\n",
    "#     # Plotting lineplot of fraction of total variance vs. number of principal components\n",
    "#     # For all possible numbers of principal components\n",
    "#     ax.plot(np.cumsum(PCA().fit(industry_train).explained_variance_ratio_))\n",
    "#     # Labels\n",
    "#     ax.set_title('Fraction of total variance vs. number of principal components')\n",
    "#     ax.set_xlabel('k = number of components')\n",
    "#     ax.set_ylabel('Cumulative explained variance')\n",
    "#     # Display\n",
    "#     plt.show()\n",
    "    \n",
    "    # create PCA features for train and test set\n",
    "    n_components=10\n",
    "    pca = PCA(n_components=n_components, whiten=True, random_state=random.seed(1234)) \n",
    "    pca_train = pca.fit_transform(industry_train)\n",
    "    pca_test = pca.transform(industry_test)\n",
    "    # create dataframes from numpy\n",
    "    df_ind_train = pd.DataFrame(pca_train,columns=['ind_pca'+ str(x) for x in range(n_components)])\n",
    "    df_ind_test = pd.DataFrame(pca_test,columns=['ind_pca'+ str(x) for x in range(n_components)])\n",
    "    # drop country prefix columns\n",
    "    X_train = X_train.drop(list(X_train.filter(regex='^ind_',axis=1).columns), axis=1)\n",
    "    X_test = X_test.drop(list(X_test.filter(regex='^ind_',axis=1).columns), axis=1)\n",
    "    # concat with train dataset\n",
    "    X_train = pd.concat([X_train, df_ind_train],axis = 1)\n",
    "    X_test = pd.concat([X_test, df_ind_test],axis = 1)\n",
    "    del df_ind_train,df_ind_test,industry_train,industry_test\n",
    "\n",
    "    return X_train,X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIZUALIZE COUNTRY INDUSTRY PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 985
    },
    "id": "UYBtgwajQZ8L",
    "outputId": "6174a13c-5e59-4e88-e92e-72c577ebe7fa"
   },
   "outputs": [],
   "source": [
    "# create graphs for PCA analysis for country and industry features\n",
    "def Visualize_Country_Ind_PCA(X,y):\n",
    "    print(\"None\")\n",
    "#     Country_df = X.filter(regex='^country',axis=1).fillna(0)\n",
    "#     pca_new_Country = PCA(n_components=10,random_state=random.seed(1234))  \n",
    "#     Country_df_PCA = pca_new_Country.fit_transform(Country_df)\n",
    "\n",
    "#     Industry_df = X.filter(regex='^ind_',axis=1).fillna(0)\n",
    "#     pca_new_Industry_df = PCA(n_components=30,random_state=random.seed(1234))  \n",
    "#     Industry_df_PCA = pca_new_Industry_df.fit_transform(Industry_df)\n",
    "\n",
    "#     # The PCA model\n",
    "#     fig, axes = plt.subplots(1,2,figsize=(15,15))\n",
    "#     colors = ['r','g']\n",
    "#     fig.suptitle('PCA Analysis for Country and Industry', fontsize=30)\n",
    "#     targets = [1,0]\n",
    "#     for target, color in zip(targets,colors):\n",
    "#       indexes = np.where(y == target)\n",
    "#       axes[0].scatter(Country_df_PCA[indexes][:,0], Country_df_PCA[indexes][:,1],color=color)\n",
    "#       axes[0].set_xlabel('PC1')\n",
    "#       axes[0].set_ylabel('PC2')\n",
    "#       axes[0].set_title('PCA-Country')\n",
    "#       axes[1].scatter(Industry_df_PCA[indexes][:,0], Industry_df_PCA[indexes][:,1], color=color)\n",
    "#       axes[1].set_xlabel('PC1')\n",
    "#       axes[1].set_ylabel('PC2')\n",
    "#       axes[1].set_title('PCA-Industry')\n",
    "#     plt.axis('tight')\n",
    "\n",
    "#     out_labels = ['p1','non-p1']\n",
    "#     plt.legend(out_labels,prop={'size':10},loc='upper right',title='Legend of plot')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmnuF44ge7ve",
    "outputId": "ac7feb4d-171c-455d-faf1-df090485dad0"
   },
   "outputs": [],
   "source": [
    "def Run_Classifier(X_train,X_test,y_train,y_test,numeric_features,categorical_features,n_deg,Type,col_graph):\n",
    "    \n",
    "    results = OrderedDict()\n",
    "    results['n_deg'] = n_deg\n",
    "    results['Model_Type'] = Type\n",
    "    results['Column_Name'] = col_graph\n",
    "    classifier_list = []\n",
    "    LRR = LogisticRegression(max_iter=10000, tol=0.1)\n",
    "    KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "    BNB = BernoulliNB()\n",
    "    GNB = GaussianNB()\n",
    "    SVM = svm.SVC()\n",
    "    DCT = DecisionTreeClassifier()\n",
    "    XGB = xgb.XGBRegressor() #tree_method='gpu_hist', gpu_id=0\n",
    "    RMF = RandomForestClassifier()\n",
    "\n",
    "    #classifier\n",
    "    classifier_list.append(('LRR', LRR, {'classifier__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000],\\\n",
    "                                        'classifier__random_state': [random.seed(1234)]}))\n",
    "    classifier_list.append(('KNN', KNN, {}))\n",
    "    classifier_list.append(('BNB', BNB, {'classifier__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]}))\n",
    "    classifier_list.append(('GNB', GNB, {'classifier__var_smoothing': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]}))\n",
    "    classifier_list.append(('DCT', DCT, {'classifier__max_depth':np.arange(1, 21),\n",
    "                                        'classifier__min_samples_leaf':[1, 5, 10, 20, 50, 100],\n",
    "                                        'classifier__random_state' : [random.seed(1234)]}))\n",
    "    classifier_list.append(('XGB', XGB, {'classifier__random_state' : [random.seed(1234)]}))\n",
    "    classifier_list.append(('RMF', RMF, {'classifier__random_state' : [random.seed(1234)]}))\n",
    "    classifier_list.append(('SVM', SVM, {'classifier__random_state' : [random.seed(1234)]}))\n",
    "\n",
    "    encoder_list = [ce.one_hot.OneHotEncoder]\n",
    "    scaler_list = [StandardScaler()]\n",
    "\n",
    "    for label, classifier, params in classifier_list:\n",
    "        results[label] = {}\n",
    "        for encoder in encoder_list:\n",
    "            for feature_scaler in scaler_list:\n",
    "                results[label][f'{encoder.__name__} with {feature_scaler}'] = {}\n",
    "                print('{} with {} and {}'.format(label,encoder.__name__,feature_scaler))\n",
    "\n",
    "                numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
    "\n",
    "                categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                                          ('woe', encoder())])\n",
    "\n",
    "                preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),\n",
    "                                                               ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "                pipe = Pipeline(steps=[#('preprocessor', preprocessor),\n",
    "                                       ('scaler', feature_scaler),\n",
    "                                       ('classifier', classifier)])\n",
    "\n",
    "                if params != {}:\n",
    "                    search = RandomizedSearchCV(pipe, params, n_jobs=-1)\n",
    "                    search.fit(X_train, y_train)\n",
    "                    print('Best parameter (CV score={:.3f}): {}'.format(search.best_score_, search.best_params_))\n",
    "                    model = search.fit(X_train, y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    if label == 'XGB':\n",
    "                        y_pred = [round(value) for value in y_pred]\n",
    "                    score = f1_score(y_test, y_pred,average='weighted')\n",
    "                    print('Best score: {:.4f}\\n'.format(score))\n",
    "                    results[label][f'{encoder.__name__} with {feature_scaler}']['score'] = score\n",
    "                    try:\n",
    "                        results[label][f'{encoder.__name__} with {feature_scaler}']['best_params'] = search.best_params_\n",
    "                    except:\n",
    "                        print('Something went wrong w/ GridSearch or pipeline fitting.')\n",
    "                else:\n",
    "                    try:\n",
    "                        model = pipe.fit(X_train, y_train)\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        if label == 'XGB':\n",
    "                            y_pred = [round(value) for value in y_pred]\n",
    "                        score = f1_score(y_test, y_pred,average='weighted')\n",
    "                        print('Score: {:.4f}\\n'.format(score))\n",
    "                        results[label][f'{encoder.__name__} with {feature_scaler}']['score'] = score\n",
    "                    except:\n",
    "                        print('Something went wrong with pipeline fitting')\n",
    "    print(results)\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_Output(out_list,iteration):\n",
    "    # encode to encode int/float and array types and write the output json\n",
    "    class NpEncoder(json.JSONEncoder):\n",
    "        def default(self, obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            else:\n",
    "                return super(NpEncoder, self).default(obj)\n",
    "    # File is saved under Files directory. /content would be the baseline folder\n",
    "    # You can click on folder icon on left side of the directory structure to\n",
    "    # see the created file\n",
    "    with open(f'files/output/results_baseline_ITER_{iteration}.json', 'w') as fp:\n",
    "        json.dump(out_list, fp, sort_keys=False, indent=4, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDUCE MEMORY USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100*(start_mem-end_mem)/start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndeg and set- 4 - G+BL\n",
      "\n",
      "DEGREE:4:ITERATION:1 BEGIN...\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE:START...\n",
      "Original DF shape (1131345, 3)\n",
      "Original Model_DF_D4 shape (1131345, 3)\n",
      "Original DF_GR shape after merge (10504, 41)\n",
      "Mem. usage decreased to  1.46 Mb (56.5% reduction)\n",
      "Graph shape after merge (10504, 41)\n",
      "['tri_0', 'spath_top_3_4', 'w_spath_top_1_1', 'kc_0', 'spath_top_1_3', 'w_spath_top_3_0', 'in_deg_0', 'spath_top_3_3', 'uuid', 'kc_1', 'pr_1', 'spath_top_1_4', 'out_deg_0', 'out_deg_1', 'pr_2', 'spath_top_min_3', 'w_spath_top_1_3', 'w_spath_top_min_1', 'w_spath_top_3_1', 'spath_top_min_1', 'pr_0', 'in_deg_1', 'pr_3', 'w_spath_top_min_3', 'w_spath_top_3_2', 'w_spath_top_3_3', 'spath_top_1_2', 'spath_top_1_1', 'spath_top_3_2', 'w_spath_top_1_0', 'spath_top_3_0', 'w_spath_top_1_4', 'spath_top_3_1', 'spath_top_1_0', 'kc_2', 'w_spath_top_1_2', 'w_spath_top_3_4', 'kc_3', 'tri_1']\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'tri_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['tri_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['tri_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.706): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7156\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7205\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.623): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6284\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.646): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6394\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.746): {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 7}\n",
      "Best score: 0.7418\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.394): {'classifier__random_state': None}\n",
      "Best score: 0.7970\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.797): {'classifier__random_state': None}\n",
      "Best score: 0.8099\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.725): {'classifier__random_state': None}\n",
      "Best score: 0.7355\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'tri_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7155582854181559, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7205269212330991}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.628379573174054, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6393513657983975, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7417634327453515, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 4}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7969929754008378, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.809869674195025, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7355209128586014, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_3_4'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_3_4', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_3_4', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.772): {'classifier__random_state': None, 'classifier__C': 100.0}\n",
      "Best score: 0.7611\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7536\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.662): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6302\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.732): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7059\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.786): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 13}\n",
      "Best score: 0.7666\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.487): {'classifier__random_state': None}\n",
      "Best score: 0.8122\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.832): {'classifier__random_state': None}\n",
      "Best score: 0.8178\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.786): {'classifier__random_state': None}\n",
      "Best score: 0.7742\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_3_4'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7611379520317121, 'best_params': {'classifier__random_state': None, 'classifier__C': 100.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7535977929989917}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6302277713467396, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7059118999906662, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7665935360327453, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 14}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8122089045811041, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8177926691994036, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7741933401665752, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_1_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_1_1', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_1_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.771): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7548\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7495\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.650): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6378\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.734): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7285\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.787): {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 8}\n",
      "Best score: 0.7778\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.489): {'classifier__random_state': None}\n",
      "Best score: 0.8271\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.821): {'classifier__random_state': None}\n",
      "Best score: 0.8274\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.774): {'classifier__random_state': None}\n",
      "Best score: 0.7785\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_1_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7548328917809515, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7494759251954631}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6377619151205413, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7284994508709548, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7777834566451848, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 12}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8270791885515499, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8274155314529631, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7785093492818825, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'kc_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['kc_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['kc_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.711): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7049\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7088\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.625): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6190\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.642): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6213\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.747): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 11}\n",
      "Best score: 0.7377\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.407): {'classifier__random_state': None}\n",
      "Best score: 0.8075\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.807): {'classifier__random_state': None}\n",
      "Best score: 0.8137\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.741): {'classifier__random_state': None}\n",
      "Best score: 0.7201\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'kc_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7049367958834271, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7087558734622539}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.619000334213166, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6212937057987028, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7377299200507504, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 12}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8074928119540917, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8136687296168297, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7200864559484667, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_1_3'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_1_3', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_1_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.768): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7647\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7359\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.642): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6246\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.731): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7092\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.787): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 8}\n",
      "Best score: 0.7809\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.492): {'classifier__random_state': None}\n",
      "Best score: 0.8086\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.831): {'classifier__random_state': None}\n",
      "Best score: 0.8252\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.780): {'classifier__random_state': None}\n",
      "Best score: 0.7711\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_1_3'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7646745998812637, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7359007290237888}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6245910283508282, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7091522193890899, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7809498670738523, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 12}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8085519587535017, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8251891753281836, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7711198739969599, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_3_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_3_0', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_3_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.776): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7612\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7476\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.654): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6057\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.743): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7232\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.796): {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 15}\n",
      "Best score: 0.7748\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.499): {'classifier__random_state': None}\n",
      "Best score: 0.8104\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.834): {'classifier__random_state': None}\n",
      "Best score: 0.8178\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.781): {'classifier__random_state': None}\n",
      "Best score: 0.7822\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_3_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7611852322367121, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7476197666953746}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6057339399221432, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7231861505481071, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.774829151935186, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 10}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8104272124211817, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8178372236620475, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7822053405401763, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'in_deg_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['in_deg_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['in_deg_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.708): {'classifier__random_state': None, 'classifier__C': 0.01}\n",
      "Best score: 0.7043\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7000\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.609): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.5742\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.656): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6174\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.778): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 8}\n",
      "Best score: 0.7562\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.421): {'classifier__random_state': None}\n",
      "Best score: 0.7946\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.808): {'classifier__random_state': None}\n",
      "Best score: 0.8026\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.726): {'classifier__random_state': None}\n",
      "Best score: 0.7251\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'in_deg_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7043458572510507, 'best_params': {'classifier__random_state': None, 'classifier__C': 0.01}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7000252558571892}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.5741754691060632, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6174095386786895, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7561790487962604, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 9}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7945614009093771, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8025831794155908, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.725056786520344, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_3_3'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_3_3', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_3_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.770): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7630\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7341\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.645): {'classifier__alpha': 1.0}\n",
      "Best score: 0.6196\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.725): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6989\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.795): {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 7}\n",
      "Best score: 0.7516\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.505): {'classifier__random_state': None}\n",
      "Best score: 0.8013\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.834): {'classifier__random_state': None}\n",
      "Best score: 0.8142\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.781): {'classifier__random_state': None}\n",
      "Best score: 0.7717\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_3_3'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7629543989963948, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7341111012016097}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6195711784379748, 'best_params': {'classifier__alpha': 1.0}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6988793082349815, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7515618234759379, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 8}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8013345057611809, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8141848746575543, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7717437510989128, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'uuid'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 263)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 3)\n",
      "df_simple shape (10671, 263)\n",
      "(4052, 263)\n",
      "Training data shape: (6483, 262)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 262)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 262)\n",
      "\n",
      "Before pca dataset shape (1621, 262)\n",
      "Train set columns list Index(['rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0',\n",
      "       'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6',\n",
      "       'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1',\n",
      "       'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5',\n",
      "       'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9',\n",
      "       'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13',\n",
      "       'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 29)\n",
      "\n",
      "Final test dataset shape (1621, 29)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.697): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7070\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7113\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.631): {'classifier__alpha': 10.0}\n",
      "Best score: 0.6211\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.641): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6054\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.743): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 11}\n",
      "Best score: 0.7321\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.389): {'classifier__random_state': None}\n",
      "Best score: 0.7908\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.793): {'classifier__random_state': None}\n",
      "Best score: 0.7914\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.721): {'classifier__random_state': None}\n",
      "Best score: 0.7270\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'uuid'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7069616375355202, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7112886683284764}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6210929150817012, 'best_params': {'classifier__alpha': 10.0}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6054043667089725, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7321213190165022, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 7}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7908300330968281, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7914084686983419, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7269738272177279, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'kc_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['kc_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['kc_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.695): {'classifier__random_state': None, 'classifier__C': 0.1}\n",
      "Best score: 0.7074\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7094\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.616): {'classifier__alpha': 1.0}\n",
      "Best score: 0.6052\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.632): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6169\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.746): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 11}\n",
      "Best score: 0.7489\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.399): {'classifier__random_state': None}\n",
      "Best score: 0.7889\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.806): {'classifier__random_state': None}\n",
      "Best score: 0.8192\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.730): {'classifier__random_state': None}\n",
      "Best score: 0.7369\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'kc_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7074059440350302, 'best_params': {'classifier__random_state': None, 'classifier__C': 0.1}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7094379546550778}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6051623500696669, 'best_params': {'classifier__alpha': 1.0}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6168539050674295, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7488808555791915, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 17}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7889294843544777, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8192290789403667, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7368571275899368, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'pr_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['pr_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['pr_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.712): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7098\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.6943\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.622): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6222\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.648): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6333\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.770): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 18}\n",
      "Best score: 0.7661\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.472): {'classifier__random_state': None}\n",
      "Best score: 0.8229\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.828): {'classifier__random_state': None}\n",
      "Best score: 0.8328\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.724): {'classifier__random_state': None}\n",
      "Best score: 0.7185\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'pr_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7098375189121251, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6943006406069199}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6222254627756735, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6332629585514836, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7661363876605912, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 11}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.822948392751608, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8328062673924433, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7185265313903069, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_1_4'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_1_4', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_1_4', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.773): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7672\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7384\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.660): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6125\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.738): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7329\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.790): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 14}\n",
      "Best score: 0.7716\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.492): {'classifier__random_state': None}\n",
      "Best score: 0.8184\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.835): {'classifier__random_state': None}\n",
      "Best score: 0.8141\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.781): {'classifier__random_state': None}\n",
      "Best score: 0.7785\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_1_4'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7671649000161181, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7384097711219342}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6125156532737166, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7328962924676862, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7715664170485399, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 10}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8184331479791276, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8140867573865102, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7785317705120296, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'out_deg_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['out_deg_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['out_deg_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.709): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7068\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7044\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.624): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.5983\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.640): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6191\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.745): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 7}\n",
      "Best score: 0.7371\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.390): {'classifier__random_state': None}\n",
      "Best score: 0.7798\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.801): {'classifier__random_state': None}\n",
      "Best score: 0.8026\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.731): {'classifier__random_state': None}\n",
      "Best score: 0.7175\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'out_deg_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7068147853742153, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7044419756482915}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.5983462328725442, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6191329401924898, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7371006143949514, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 16}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7797660796922223, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8025815268137337, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7175186300132209, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'out_deg_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['out_deg_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['out_deg_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.720): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7191\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7138\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.625): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6158\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.661): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6496\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.740): {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 17}\n",
      "Best score: 0.7295\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.404): {'classifier__random_state': None}\n",
      "Best score: 0.7958\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.803): {'classifier__random_state': None}\n",
      "Best score: 0.8204\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.732): {'classifier__random_state': None}\n",
      "Best score: 0.7186\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'out_deg_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7191429549425277, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7137562865478914}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6157748015363734, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6495618481576803, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.729513310131448, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 7}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7957843861066939, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8204336237368068, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7185628432076218, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'pr_2'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['pr_2', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['pr_2', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.710): {'classifier__random_state': None, 'classifier__C': 100.0}\n",
      "Best score: 0.7156\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7088\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.618): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.5934\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.654): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6461\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.765): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 9}\n",
      "Best score: 0.7736\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.471): {'classifier__random_state': None}\n",
      "Best score: 0.8124\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.826): {'classifier__random_state': None}\n",
      "Best score: 0.8273\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.736): {'classifier__random_state': None}\n",
      "Best score: 0.7381\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'pr_2'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7155582854181559, 'best_params': {'classifier__random_state': None, 'classifier__C': 100.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7087991065354873}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.5934443715401698, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6461422743470432, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7735763808900559, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 12}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8124447415591226, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8272661987290387, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7381154968620539, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_min_3'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_min_3', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_min_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.773): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7569\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7556\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.649): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6053\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.734): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7232\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.789): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 18}\n",
      "Best score: 0.7772\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.490): {'classifier__random_state': None}\n",
      "Best score: 0.7951\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.828): {'classifier__random_state': None}\n",
      "Best score: 0.8154\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.784): {'classifier__random_state': None}\n",
      "Best score: 0.7693\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_min_3'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7569055611557315, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.755576134402154}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6053316793489949, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7231741422820358, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7771855314817778, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 15}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7951379486820044, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8153672199150923, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7692690909419717, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_1_3'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_1_3', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_1_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.765): {'classifier__random_state': None, 'classifier__C': 0.1}\n",
      "Best score: 0.7605\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7481\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.646): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6108\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.727): {'classifier__var_smoothing': 0.001}\n",
      "Best score: 0.6900\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.795): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 7}\n",
      "Best score: 0.7690\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.479): {'classifier__random_state': None}\n",
      "Best score: 0.8146\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.826): {'classifier__random_state': None}\n",
      "Best score: 0.8178\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.780): {'classifier__random_state': None}\n",
      "Best score: 0.7816\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_1_3'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7604696688158811, 'best_params': {'classifier__random_state': None, 'classifier__C': 0.1}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7481056706913628}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6107525923528254, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6899712099534536, 'best_params': {'classifier__var_smoothing': 0.001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7690272018509989, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 15}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8145887090164071, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8177926691994036, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7816093048578389, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_min_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_min_1', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_min_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.770): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7617\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7409\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.647): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6404\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.751): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7320\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.800): {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 7}\n",
      "Best score: 0.7746\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.497): {'classifier__random_state': None}\n",
      "Best score: 0.7984\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.832): {'classifier__random_state': None}\n",
      "Best score: 0.8264\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.782): {'classifier__random_state': None}\n",
      "Best score: 0.7872\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_min_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7617344840695593, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7408941703441563}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6404118856788725, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7319897331983568, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7746291545427585, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 12}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7983755593694988, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.826424587516677, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7871672805962717, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_3_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_3_1', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_3_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.763): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7694\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7433\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.644): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6289\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.708): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7072\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.777): {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 6}\n",
      "Best score: 0.7799\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.469): {'classifier__random_state': None}\n",
      "Best score: 0.8125\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.826): {'classifier__random_state': None}\n",
      "Best score: 0.8240\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.770): {'classifier__random_state': None}\n",
      "Best score: 0.7798\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_3_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7694345203335987, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7432719614748824}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6289423633753581, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.707201796432295, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7798799257632224, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 9}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8124674175581935, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8239691888875594, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7797568598838673, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_min_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_min_1', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_min_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.769): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7581\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7716\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.644): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6135\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.739): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7227\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.785): {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 8}\n",
      "Best score: 0.7658\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.483): {'classifier__random_state': None}\n",
      "Best score: 0.8196\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.823): {'classifier__random_state': None}\n",
      "Best score: 0.8394\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.777): {'classifier__random_state': None}\n",
      "Best score: 0.7810\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_min_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.758083194466716, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7715819006749381}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6134577183350763, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7227184501408438, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7657512344985107, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 50, 'classifier__max_depth': 7}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.819587890867785, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8394306750835822, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7809988830202816, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'pr_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['pr_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['pr_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.712): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7069\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7063\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.625): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.5908\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.644): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6301\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.766): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 12}\n",
      "Best score: 0.7605\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.473): {'classifier__random_state': None}\n",
      "Best score: 0.8168\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.820): {'classifier__random_state': None}\n",
      "Best score: 0.8273\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.730): {'classifier__random_state': None}\n",
      "Best score: 0.7354\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'pr_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7068991665930892, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7062982127772344}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.5908032839628554, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6301389389619625, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7604534319319822, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 13}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8167797655768044, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8272667246409688, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7354367833586697, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'in_deg_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['in_deg_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['in_deg_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.707): {'classifier__random_state': None, 'classifier__C': 0.1}\n",
      "Best score: 0.7193\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.6964\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.618): {'classifier__alpha': 10.0}\n",
      "Best score: 0.6102\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.638): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6319\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.751): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 8}\n",
      "Best score: 0.7318\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.421): {'classifier__random_state': None}\n",
      "Best score: 0.8026\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.809): {'classifier__random_state': None}\n",
      "Best score: 0.8087\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.726): {'classifier__random_state': None}\n",
      "Best score: 0.7294\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'in_deg_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7192691095364561, 'best_params': {'classifier__random_state': None, 'classifier__C': 0.1}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6964358216855666}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6101838130214046, 'best_params': {'classifier__alpha': 10.0}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6318578155320375, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7318400502709819, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 6}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8025891901396004, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8087131448536787, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7294446523107798, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'pr_3'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['pr_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['pr_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.712): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7018\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.6810\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.615): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.5945\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.651): {'classifier__var_smoothing': 0.01}\n",
      "Best score: 0.6346\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.766): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 11}\n",
      "Best score: 0.7778\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.473): {'classifier__random_state': None}\n",
      "Best score: 0.8137\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.830): {'classifier__random_state': None}\n",
      "Best score: 0.8297\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.728): {'classifier__random_state': None}\n",
      "Best score: 0.7123\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'pr_3'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7017583548470308, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6810326673573813}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.5945450931205493, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6346005708178097, 'best_params': {'classifier__var_smoothing': 0.01}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7777900377203727, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 50, 'classifier__max_depth': 13}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8136935481942478, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8297349908382965, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7123403013109727, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_min_3'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_min_3', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_min_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.773): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7642\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7508\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.650): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6288\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.746): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7438\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.792): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 10}\n",
      "Best score: 0.7623\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.494): {'classifier__random_state': None}\n",
      "Best score: 0.8051\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.828): {'classifier__random_state': None}\n",
      "Best score: 0.8333\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.785): {'classifier__random_state': None}\n",
      "Best score: 0.7822\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_min_3'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7642035567735016, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7507544347567636}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6288131616557076, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7437798095597566, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7623445132009727, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 7}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8051171981595957, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8332810971662467, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7822262274737657, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_3_2'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_3_2', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_3_2', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.774): {'classifier__random_state': None, 'classifier__C': 0.1}\n",
      "Best score: 0.7641\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7495\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.649): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6062\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.733): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7045\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.787): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 7}\n",
      "Best score: 0.7772\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.490): {'classifier__random_state': None}\n",
      "Best score: 0.8117\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.835): {'classifier__random_state': None}\n",
      "Best score: 0.8283\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.780): {'classifier__random_state': None}\n",
      "Best score: 0.7816\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_3_2'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7641236263611341, 'best_params': {'classifier__random_state': None, 'classifier__C': 0.1}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7495150166875123}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6062230820709014, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7044995832627234, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7772296352388969, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 11}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8117030947578601, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.828254149050736, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7816038186486387, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_3_3'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_3_3', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_3_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.773): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7710\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7488\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.655): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6128\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.734): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7049\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.789): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 6}\n",
      "Best score: 0.7784\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.484): {'classifier__random_state': None}\n",
      "Best score: 0.8158\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.832): {'classifier__random_state': None}\n",
      "Best score: 0.8326\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.780): {'classifier__random_state': None}\n",
      "Best score: 0.7754\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_3_3'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7710374450088202, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7487641996696}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6127888666660972, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7048773204472117, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7783652820264649, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 8}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8158049839060646, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.832644115044428, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7754452037837953, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_1_2'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_1_2', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_1_2', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.769): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7550\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7673\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.648): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6292\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.741): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7296\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.783): {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 9}\n",
      "Best score: 0.7821\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.489): {'classifier__random_state': None}\n",
      "Best score: 0.8048\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.827): {'classifier__random_state': None}\n",
      "Best score: 0.8290\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.778): {'classifier__random_state': None}\n",
      "Best score: 0.7840\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_1_2'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7550143080051026, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7672828090305629}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6292069505461936, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7295866991951727, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7821350266560761, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 8}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8047594983363702, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8289651392009426, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7840390258866387, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_1_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_1_1', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_1_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.772): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7752\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7592\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.647): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6234\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.739): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7237\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.794): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 16}\n",
      "Best score: 0.7798\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.479): {'classifier__random_state': None}\n",
      "Best score: 0.8202\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.829): {'classifier__random_state': None}\n",
      "Best score: 0.8295\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.789): {'classifier__random_state': None}\n",
      "Best score: 0.7927\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_1_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.775202945117015, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7591838070179118}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6234365678454331, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7237133778106715, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7798265244066455, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 18}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8201790150270055, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8294567180807924, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7927066586095858, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_3_2'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_3_2', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_3_2', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.768): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7675\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7622\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.647): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6332\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.742): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7295\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.788): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 10}\n",
      "Best score: 0.7673\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.496): {'classifier__random_state': None}\n",
      "Best score: 0.8250\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.834): {'classifier__random_state': None}\n",
      "Best score: 0.8246\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.780): {'classifier__random_state': None}\n",
      "Best score: 0.7779\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_3_2'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7675407564821481, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7621615868918282}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6331508994169097, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7295359471687111, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7673334364461998, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 7}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.824985271119321, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.824579222204041, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7778976236287616, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_1_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_1_0', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_1_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.774): {'classifier__random_state': None, 'classifier__C': 0.1}\n",
      "Best score: 0.7532\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7439\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.652): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6273\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.752): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7317\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.800): {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 8}\n",
      "Best score: 0.7674\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.489): {'classifier__random_state': None}\n",
      "Best score: 0.8062\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.832): {'classifier__random_state': None}\n",
      "Best score: 0.8068\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.786): {'classifier__random_state': None}\n",
      "Best score: 0.7748\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_1_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7531682924057903, 'best_params': {'classifier__random_state': None, 'classifier__C': 0.1}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7438559433931796}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6273346771617168, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7316505194501779, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7674243275011761, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 19}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8062449273679199, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8067769626837689, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7748306944076752, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_3_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_3_0', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_3_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.769): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7573\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7538\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.663): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6323\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.744): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7225\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.780): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 13}\n",
      "Best score: 0.7618\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.490): {'classifier__random_state': None}\n",
      "Best score: 0.8252\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.834): {'classifier__random_state': None}\n",
      "Best score: 0.8240\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.778): {'classifier__random_state': None}\n",
      "Best score: 0.7767\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_3_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.757340432151518, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7538088000166205}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6322968838961288, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7224744435217609, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7618481963472542, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 8}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8251891753281836, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8239691888875594, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7766768116142262, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_1_4'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_1_4', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_1_4', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.774): {'classifier__random_state': None, 'classifier__C': 100.0}\n",
      "Best score: 0.7728\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7519\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.660): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6477\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.746): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7571\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.787): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 15}\n",
      "Best score: 0.7810\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.484): {'classifier__random_state': None}\n",
      "Best score: 0.8095\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.833): {'classifier__random_state': None}\n",
      "Best score: 0.8263\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.788): {'classifier__random_state': None}\n",
      "Best score: 0.7964\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_1_4'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7728011931726017, 'best_params': {'classifier__random_state': None, 'classifier__C': 100.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7519118473867854}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6476528263037229, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7570849675312157, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7809823797945291, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 10}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8095362296182506, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8262637402985278, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7963866280283664, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_3_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_3_1', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_3_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.773): {'classifier__random_state': None, 'classifier__C': 0.1}\n",
      "Best score: 0.7562\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7487\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.646): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6127\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.736): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7043\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.791): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 7}\n",
      "Best score: 0.7655\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.490): {'classifier__random_state': None}\n",
      "Best score: 0.8122\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.829): {'classifier__random_state': None}\n",
      "Best score: 0.8103\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.783): {'classifier__random_state': None}\n",
      "Best score: 0.7835\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_3_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7561863114656698, 'best_params': {'classifier__random_state': None, 'classifier__C': 0.1}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7487316707096693}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6127404481452625, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7043322148183122, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7655280852483506, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 11}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.812225646302917, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8103292529424023, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7834658419979458, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'spath_top_1_0'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['spath_top_1_0', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['spath_top_1_0', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.768): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7629\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7377\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.641): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6443\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.713): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6912\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.788): {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 7}\n",
      "Best score: 0.7740\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.493): {'classifier__random_state': None}\n",
      "Best score: 0.8077\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.829): {'classifier__random_state': None}\n",
      "Best score: 0.8176\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.776): {'classifier__random_state': None}\n",
      "Best score: 0.7816\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'spath_top_1_0'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7629061902304707, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7377357201565959}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6443178820879744, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6912167096698677, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7739677964638118, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 7}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8077153851702567, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.817607841238668, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7815783827940657, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'kc_2'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['kc_2', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['kc_2', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.702): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7088\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.6811\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.625): {'classifier__alpha': 10.0}\n",
      "Best score: 0.6182\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.644): {'classifier__var_smoothing': 0.001}\n",
      "Best score: 0.6401\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.742): {'classifier__random_state': None, 'classifier__min_samples_leaf': 20, 'classifier__max_depth': 4}\n",
      "Best score: 0.7292\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.402): {'classifier__random_state': None}\n",
      "Best score: 0.7766\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.803): {'classifier__random_state': None}\n",
      "Best score: 0.7834\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.728): {'classifier__random_state': None}\n",
      "Best score: 0.7249\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'kc_2'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7087558734622539, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6810530623256549}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6182192907229991, 'best_params': {'classifier__alpha': 10.0}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6400904172927695, 'best_params': {'classifier__var_smoothing': 0.001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7291640583252328, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 7}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7766492719248093, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7834450740889715, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7248818406546278, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_1_2'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_1_2', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_1_2', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.775): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7765\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7709\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.652): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6212\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.743): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7235\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.796): {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 6}\n",
      "Best score: 0.7798\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.486): {'classifier__random_state': None}\n",
      "Best score: 0.8332\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.828): {'classifier__random_state': None}\n",
      "Best score: 0.8320\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.789): {'classifier__random_state': None}\n",
      "Best score: 0.7908\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_1_2'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7764559761621654, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7709410037933456}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6212075586208445, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7234886895298208, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7797655768044418, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 9}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8331805840215821, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8319913677447154, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7908300330968281, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'w_spath_top_3_4'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['w_spath_top_3_4', 'rank', 'employee_count_ord', 'total_funding_usd',\n",
      "       'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4',\n",
      "       'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9',\n",
      "       'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3',\n",
      "       'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7',\n",
      "       'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11',\n",
      "       'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['w_spath_top_3_4', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.773): {'classifier__random_state': None, 'classifier__C': 10.0}\n",
      "Best score: 0.7624\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.7493\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.650): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6276\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.729): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.7210\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.785): {'classifier__random_state': None, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 12}\n",
      "Best score: 0.7736\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.468): {'classifier__random_state': None}\n",
      "Best score: 0.8129\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.827): {'classifier__random_state': None}\n",
      "Best score: 0.8319\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.784): {'classifier__random_state': None}\n",
      "Best score: 0.7767\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'w_spath_top_3_4'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.762419417083034, 'best_params': {'classifier__random_state': None, 'classifier__C': 10.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7492648233997474}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6276406393545481, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7210269586930912, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7735922370660374, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 10, 'classifier__max_depth': 9}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.812851453448879, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.8318937628415424, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7766815710054088, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'kc_3'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['kc_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['kc_3', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.707): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7119\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.6970\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.625): {'classifier__alpha': 10.0}\n",
      "Best score: 0.6124\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.641): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6227\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.744): {'classifier__random_state': None, 'classifier__min_samples_leaf': 50, 'classifier__max_depth': 6}\n",
      "Best score: 0.7309\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.385): {'classifier__random_state': None}\n",
      "Best score: 0.7797\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.793): {'classifier__random_state': None}\n",
      "Best score: 0.7859\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.726): {'classifier__random_state': None}\n",
      "Best score: 0.7237\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'kc_3'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7118733338041421, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6970262964151723}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6124422981037134, 'best_params': {'classifier__alpha': 10.0}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6227018491362956, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7309089688378709, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 50, 'classifier__max_depth': 6}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7797484777088645, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7858938686861338, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7236767671746694, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "Get these columns:  Index(['__id', 'p1_tag', 'tri_1'], dtype='object')\n",
      "Original DF shape (1131345, 264)\n",
      "Mem. usage decreased to 350.65 Mb (48.2% reduction)\n",
      "\n",
      "Dataframe shape: (1131345, 264)\n",
      "Merged shape after baseline and graph (10671, 264)\n",
      "df_bo shape (1131345, 264)\n",
      "df_temp shape (10504, 4)\n",
      "df_simple shape (10671, 264)\n",
      "(4052, 264)\n",
      "Training data shape: (6483, 263)\n",
      "Train label shape: (6483,)\n",
      "Test data shape: (1621, 263)\n",
      "Test label shape: (1621,)\n",
      "Before pca dataset shape (6483, 263)\n",
      "\n",
      "Before pca dataset shape (1621, 263)\n",
      "Train set columns list Index(['tri_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age',\n",
      "       'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5',\n",
      "       'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0',\n",
      "       'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4',\n",
      "       'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8',\n",
      "       'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12',\n",
      "       'cntry_pca_13', 'cntry_pca_14'],\n",
      "      dtype='object')\n",
      "Final train dataset shape (6483, 30)\n",
      "\n",
      "Final test dataset shape (1621, 30)\n",
      "\n",
      "Test Dataframe Columns:\n",
      "\n",
      "['tri_1', 'rank', 'employee_count_ord', 'total_funding_usd', 'age', 'ind_pca0', 'ind_pca1', 'ind_pca2', 'ind_pca3', 'ind_pca4', 'ind_pca5', 'ind_pca6', 'ind_pca7', 'ind_pca8', 'ind_pca9', 'cntry_pca_0', 'cntry_pca_1', 'cntry_pca_2', 'cntry_pca_3', 'cntry_pca_4', 'cntry_pca_5', 'cntry_pca_6', 'cntry_pca_7', 'cntry_pca_8', 'cntry_pca_9', 'cntry_pca_10', 'cntry_pca_11', 'cntry_pca_12', 'cntry_pca_13', 'cntry_pca_14']\n",
      "LRR with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.712): {'classifier__random_state': None, 'classifier__C': 1.0}\n",
      "Best score: 0.7124\n",
      "\n",
      "KNN with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score: 0.6946\n",
      "\n",
      "BNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.613): {'classifier__alpha': 0.0001}\n",
      "Best score: 0.6123\n",
      "\n",
      "GNB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.656): {'classifier__var_smoothing': 0.0001}\n",
      "Best score: 0.6508\n",
      "\n",
      "DCT with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.750): {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 20}\n",
      "Best score: 0.7551\n",
      "\n",
      "XGB with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.404): {'classifier__random_state': None}\n",
      "Best score: 0.7816\n",
      "\n",
      "RMF with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.801): {'classifier__random_state': None}\n",
      "Best score: 0.7939\n",
      "\n",
      "SVM with OneHotEncoder and StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Best parameter (CV score=0.733): {'classifier__random_state': None}\n",
      "Best score: 0.7263\n",
      "\n",
      "OrderedDict([('n_deg', 4), ('Model_Type', 'G+BL'), ('Column_Name', 'tri_1'), ('LRR', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7124349212367895, 'best_params': {'classifier__random_state': None, 'classifier__C': 1.0}}}), ('KNN', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.694632245338139}}), ('BNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6122626519096396, 'best_params': {'classifier__alpha': 0.0001}}}), ('GNB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.6508440196763338, 'best_params': {'classifier__var_smoothing': 0.0001}}}), ('DCT', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7550894509561998, 'best_params': {'classifier__random_state': None, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 12}}}), ('XGB', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7816167849058415, 'best_params': {'classifier__random_state': None}}}), ('RMF', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7939359989498256, 'best_params': {'classifier__random_state': None}}}), ('SVM', {'OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)': {'score': 0.7263438136826393, 'best_params': {'classifier__random_state': None}}})])\n",
      "\n",
      "DEGREE:4:GRAPH+BASELINE SET UP:END\n",
      "\n",
      "ITERATION:1:DEGREE:4:END\n",
      "Completed all runs!....\n"
     ]
    }
   ],
   "source": [
    "'''Data analysis'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import statistics\n",
    "from collections import OrderedDict \n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "'''Plotting'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "'''Stat'''\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "'''ML'''\n",
    "import prince\n",
    "import category_encoders as ce\n",
    "from sklearn import metrics, svm, preprocessing, utils\n",
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,\\\n",
    "MaxAbsScaler,RobustScaler,QuantileTransformer,PowerTransformer\n",
    "from libsvm.svmutil import *\n",
    "\n",
    "#list_Set_Up = ['BL_Only','G_Only','G+BL','G+BL_Red','BL_Red_Only']\n",
    "#list_Set_Up = ['BL_Only','G+BL']\n",
    "list_Set_Up = ['G+BL']\n",
    "degrees = [4]\n",
    "\n",
    "\n",
    "# Defining main function \n",
    "def main():\n",
    "    final_out = []\n",
    "    df = pd.read_csv('files/output/baseline_fixed.csv', sep=';')\n",
    "    df = pd.concat([df,pd.get_dummies(df['country_code'], prefix='country')],axis=1).drop('country_code',axis=1)\n",
    "    # Testing for 3 iterations for now\n",
    "    for iteration in range(1):\n",
    "        out_dict = {}\n",
    "        out_dict['iteration'] = iteration+1\n",
    "        out_list = []\n",
    "        for n_deg in degrees:\n",
    "            for setup_Type in list_Set_Up:\n",
    "                print(\"ndeg and set-\",n_deg,\"-\",setup_Type)\n",
    "                print(f\"\\nDEGREE:{n_deg}:ITERATION:{iteration+1} BEGIN...\")\n",
    "                #print(\"n_deg\",n_deg)\n",
    "                if setup_Type == 'BL_Only':\n",
    "                    print(f\"\\nDEGREE:{n_deg}:BASELINE_ONLY SET UP:START...\")\n",
    "                    df_bo = Baseline_Only(df)\n",
    "                    df_bo = df_bo.drop(['uuid'],axis=1)\n",
    "                    df_simple = df_bo\n",
    "                    X_train,X_test,X,y,y_train,y_test,numeric_features,\\\n",
    "                    categorical_features = gen_Train_Test_Split(df_simple)\n",
    "                    X_train,X_test = PCA_Industry(X_train,X_test)\n",
    "                    X_train,X_test = PCA_Country(X_train,X_test)\n",
    "\n",
    "                    #Visualize_Country_Ind_PCA(X,y)\n",
    "                    print(\"Final train dataset shape\",X_train.shape)\n",
    "                    print(\"\\nFinal test dataset shape\",X_test.shape)\n",
    "                    #print('\\nTrain Dataframe Columns:\\n\\n{}'.format(X_train.columns.to_list()))\n",
    "                    print('\\nTest Dataframe Columns:\\n\\n{}'.format(X_test.columns.to_list()))\n",
    "                    col_graph = 'None'\n",
    "                    results = Run_Classifier(X_train,X_test,y_train,y_test,numeric_features,categorical_features,n_deg,setup_Type,col_graph)\n",
    "                    out_list.append(results)\n",
    "                    print(f\"\\nDEGREE:{n_deg}:BASELINE_ONLY SET UP:END\")\n",
    "\n",
    "                elif setup_Type == 'G_Only':\n",
    "                    print(f\"\\nDEGREE:{n_deg}:BASELINE_ONLY SET UP:START...\")\n",
    "                    df_gr = Graph_Only(df,n_deg)\n",
    "                    df_gr = df_gr.drop(['uuid','__id'],axis=1)\n",
    "                    df_simple = df_gr\n",
    "                    X_train,X_test,X,y,y_train,y_test,numeric_features,\\\n",
    "                    categorical_features = gen_Train_Test_Split(df_simple)\n",
    "                    print(\"Final train dataset shape\",X_train.shape)\n",
    "                    print(\"\\nFinal test dataset shape\",X_test.shape)\n",
    "                    #print('\\nTrain Dataframe Columns:\\n\\n{}'.format(X_train.columns.to_list()))\n",
    "                    print('\\nTest Dataframe Columns:\\n\\n{}'.format(X_test.columns.to_list()))\n",
    "                    col_graph = 'None'\n",
    "                    results = Run_Classifier(X_train,X_test,y_train,y_test,numeric_features,categorical_features,n_deg,setup_Type,col_graph)\n",
    "                    out_list.append(results)\n",
    "                    print(f\"\\nDEGREE:{n_deg}:BASELINE_ONLY SET UP:END\")\n",
    "                elif setup_Type == 'G+BL':   \n",
    "                    print(f\"\\nDEGREE:{n_deg}:GRAPH+BASELINE:START...\") \n",
    "\n",
    "                    df_gr = Graph_Only(df, n_deg)\n",
    "                    print(\"Graph shape after merge\",df_gr.shape)\n",
    "\n",
    "                    graph_col_list = list(set(df_gr.columns) - {'__id'} - {'p1_tag'}) \n",
    "                    print(graph_col_list)\n",
    "                    for col_graph in graph_col_list:\n",
    "\n",
    "                        #if col_graph != 'spath_top_1_4':\n",
    "                            #break\n",
    "                        col_name = ['__id','p1_tag']\n",
    "                        col_name.append(col_graph)\n",
    "                        df_temp = df_gr[[c for c in col_name if (c in df_gr)]]\n",
    "                        print(\"Get these columns: \",df_temp.columns)\n",
    "                        df_temp['uuid'] = df_temp['__id']\n",
    "                        df_bo = Baseline_Only(df)\n",
    "                        df_simple = pd.merge(df_temp.copy(),df_bo.copy(), how = 'inner',on='uuid')\n",
    "                        df_simple = df_simple.drop(['uuid','__id','p1_tag_y'],axis=1)\n",
    "                        print(\"Merged shape after baseline and graph\",df_simple.shape)\n",
    "                        df_simple = df_simple.rename(columns={\"p1_tag_x\": \"p1_tag\"})\n",
    "\n",
    "                        print(\"df_bo shape\",df_bo.shape)\n",
    "                        print(\"df_temp shape\",df_temp.shape)\n",
    "                        print(\"df_simple shape\",df_simple.shape)\n",
    "\n",
    "                        X_train,X_test,X,y,y_train,y_test,numeric_features,\\\n",
    "                        categorical_features = gen_Train_Test_Split(df_simple)\n",
    "                        print(\"Before pca dataset shape\",X_train.shape)\n",
    "                        print(\"\\nBefore pca dataset shape\",X_test.shape)\n",
    "\n",
    "                        X_train,X_test = PCA_Industry(X_train,X_test)\n",
    "                        X_train,X_test = PCA_Country(X_train,X_test)\n",
    "                        #Visualize_Country_Ind_PCA(X)\n",
    "\n",
    "                        print(\"Train set columns list\",X_train.columns)\n",
    "\n",
    "                        print(\"Final train dataset shape\",X_train.shape)\n",
    "                        print(\"\\nFinal test dataset shape\",X_test.shape)\n",
    "                        #print('\\nTrain Dataframe Columns:\\n\\n{}'.format(X_train.columns.to_list()))\n",
    "                        print('\\nTest Dataframe Columns:\\n\\n{}'.format(X_test.columns.to_list()))\n",
    "\n",
    "                        results = Run_Classifier(X_train,X_test,y_train,y_test,numeric_features,categorical_features,n_deg,setup_Type,col_graph)\n",
    "                        out_list.append(results)\n",
    "                        print(f\"\\nDEGREE:{n_deg}:GRAPH+BASELINE SET UP:END\")\n",
    "\n",
    "                elif setup_Type == 'G+BL_Red':\n",
    "                    print(f\"\\nDEGREE:{n_deg}:GRAPH+BASELINE_REDUCED:START...\") \n",
    "                    df_gr = Graph_Only(df, n_deg)\n",
    "                    print(\"Graph shape after merge\",df_gr.shape)\n",
    "\n",
    "                    df_bo = Baseline_Reduced(df)\n",
    "                    df_temp = df_bo\n",
    "                    df_temp = df_temp.drop(['uuid'],axis=1)\n",
    "\n",
    "                    df_simple = pd.merge(df_gr.copy(),df_bo.copy(), how = 'outer',on='uuid')\n",
    "                    df_simple = df_simple.drop(['uuid','__id','p1_tag_y'],axis=1)\n",
    "                    print(\"Merged shape after baseline and graph\",df_simple.shape)\n",
    "                    #print(list(df_simple.columns))\n",
    "                    df_simple = df_simple.rename(columns={\"p1_tag_x\": \"p1_tag\"})\n",
    "\n",
    "                    X_train,X_test,X,y,y_train,y_test,numeric_features,\\\n",
    "                    categorical_features = gen_Train_Test_Split(df_simple)\n",
    "                    print(\"Before pca dataset shape\",X_train.shape)\n",
    "                    print(\"\\nBefore pca dataset shape\",X_test.shape)\n",
    "\n",
    "                    X_train,X_test = PCA_Industry(X_train,X_test)\n",
    "                    X_train,X_test = PCA_Country(X_train,X_test)\n",
    "                    #Visualize_Country_Ind_PCA(X)\n",
    "\n",
    "                    print(\"Final train dataset shape\",X_train.shape)\n",
    "                    print(\"\\nFinal test dataset shape\",X_test.shape)\n",
    "                    #print('\\nTrain Dataframe Columns:\\n\\n{}'.format(X_train.columns.to_list()))\n",
    "                    print('\\nTest Dataframe Columns:\\n\\n{}'.format(X_test.columns.to_list()))\n",
    "                    col_graph = 'None'\n",
    "                    results = Run_Classifier(X_train,X_test,y_train,y_test,numeric_features,categorical_features,setup_Type,col_graph)\n",
    "                    out_list.append(results)\n",
    "                    print(f\"\\nDEGREE:{n_deg}:GRAPH+BASELINE_REDUCED SET UP:END\")               \n",
    "                elif setup_Type == 'BL_Red_Only':\n",
    "                    print(f\"\\nDEGREE:{n_deg}:BASELINE_REDUCED_ONLY SET UP:START...\")\n",
    "\n",
    "                    df_bo = Baseline_Reduced(df)\n",
    "                    df_bo = df_bo.drop(['uuid'],axis=1)\n",
    "                    df_simple = df_bo\n",
    "                    X_train,X_test,X,y,y_train,y_test,numeric_features,\\\n",
    "                    categorical_features = gen_Train_Test_Split(df_simple)\n",
    "                    X_train,X_test = PCA_Industry(X_train,X_test)\n",
    "                    X_train,X_test = PCA_Country(X_train,X_test)\n",
    "\n",
    "                    #Visualize_Country_Ind_PCA(X,y)\n",
    "                    print(\"Final train dataset shape\",X_train.shape)\n",
    "                    print(\"\\nFinal test dataset shape\",X_test.shape)\n",
    "                    #print('\\nTrain Dataframe Columns:\\n\\n{}'.format(X_train.columns.to_list()))\n",
    "                    print('\\nTest Dataframe Columns:\\n\\n{}'.format(X_test.columns.to_list()))\n",
    "                    col_graph = 'None'\n",
    "                    results = Run_Classifier(X_train,X_test,y_train,y_test,numeric_features,categorical_features,setup_Type)\n",
    "                    out_list.append(results)\n",
    "                    print(f\"\\nDEGREE:{n_deg}:BASELINE_REDUCED_ONLY SET UP:END\")\n",
    "                    \n",
    "        out_dict['result'] = out_list\n",
    "        final_out.append(out_dict)\n",
    "        Write_Output(final_out,iteration)\n",
    "        print(f\"\\nITERATION:{iteration+1}:DEGREE:{n_deg}:END\")\n",
    "    #Write_Output(final_out)\n",
    "    print(\"Completed all runs!....\")\n",
    "if __name__ == \"__main__\":\n",
    "    # execute only if run as a script\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "g = open('files/output/results_baseline_ITER_0.json')\n",
    "data = json.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRR\n"
     ]
    }
   ],
   "source": [
    "matrix = [['Column_Name', 'LRR', 'KNN', 'BNB', 'GNB', 'DCT', 'XGB', 'RMF', 'SVM']]\n",
    "matrix_names = ['LRR', 'KNN', 'BNB', 'GNB', 'DCT', 'XGB', 'RMF', 'SVM']\n",
    "\n",
    "for j in data:\n",
    "    for k in j['result']:\n",
    "        row=[]\n",
    "        row.append(k['Column_Name'])\n",
    "        for h in matrix_names:\n",
    "            row.append(round(k[h]['OneHotEncoder with StandardScaler(copy=True, with_mean=True, with_std=True)']['score'],3))\n",
    "        matrix.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column_Name      \tLRR  \tKNN  \tBNB  \tGNB  \tDCT  \tXGB  \tRMF  \tSVM  \n",
      "tri_0            \t0.716\t0.721\t0.628\t0.639\t0.742\t0.797\t0.81 \t0.736\n",
      "spath_top_3_4    \t0.761\t0.754\t0.63 \t0.706\t0.767\t0.812\t0.818\t0.774\n",
      "w_spath_top_1_1  \t0.755\t0.749\t0.638\t0.728\t0.778\t0.827\t0.827\t0.779\n",
      "kc_0             \t0.705\t0.709\t0.619\t0.621\t0.738\t0.807\t0.814\t0.72 \n",
      "spath_top_1_3    \t0.765\t0.736\t0.625\t0.709\t0.781\t0.809\t0.825\t0.771\n",
      "w_spath_top_3_0  \t0.761\t0.748\t0.606\t0.723\t0.775\t0.81 \t0.818\t0.782\n",
      "in_deg_0         \t0.704\t0.7  \t0.574\t0.617\t0.756\t0.795\t0.803\t0.725\n",
      "spath_top_3_3    \t0.763\t0.734\t0.62 \t0.699\t0.752\t0.801\t0.814\t0.772\n",
      "uuid             \t0.707\t0.711\t0.621\t0.605\t0.732\t0.791\t0.791\t0.727\n",
      "kc_1             \t0.707\t0.709\t0.605\t0.617\t0.749\t0.789\t0.819\t0.737\n",
      "pr_1             \t0.71 \t0.694\t0.622\t0.633\t0.766\t0.823\t0.833\t0.719\n",
      "spath_top_1_4    \t0.767\t0.738\t0.613\t0.733\t0.772\t0.818\t0.814\t0.779\n",
      "out_deg_0        \t0.707\t0.704\t0.598\t0.619\t0.737\t0.78 \t0.803\t0.718\n",
      "out_deg_1        \t0.719\t0.714\t0.616\t0.65 \t0.73 \t0.796\t0.82 \t0.719\n",
      "pr_2             \t0.716\t0.709\t0.593\t0.646\t0.774\t0.812\t0.827\t0.738\n",
      "spath_top_min_3  \t0.757\t0.756\t0.605\t0.723\t0.777\t0.795\t0.815\t0.769\n",
      "w_spath_top_1_3  \t0.76 \t0.748\t0.611\t0.69 \t0.769\t0.815\t0.818\t0.782\n",
      "w_spath_top_min_1\t0.762\t0.741\t0.64 \t0.732\t0.775\t0.798\t0.826\t0.787\n",
      "w_spath_top_3_1  \t0.769\t0.743\t0.629\t0.707\t0.78 \t0.812\t0.824\t0.78 \n",
      "spath_top_min_1  \t0.758\t0.772\t0.613\t0.723\t0.766\t0.82 \t0.839\t0.781\n",
      "pr_0             \t0.707\t0.706\t0.591\t0.63 \t0.76 \t0.817\t0.827\t0.735\n",
      "in_deg_1         \t0.719\t0.696\t0.61 \t0.632\t0.732\t0.803\t0.809\t0.729\n",
      "pr_3             \t0.702\t0.681\t0.595\t0.635\t0.778\t0.814\t0.83 \t0.712\n",
      "w_spath_top_min_3\t0.764\t0.751\t0.629\t0.744\t0.762\t0.805\t0.833\t0.782\n",
      "w_spath_top_3_2  \t0.764\t0.75 \t0.606\t0.704\t0.777\t0.812\t0.828\t0.782\n",
      "w_spath_top_3_3  \t0.771\t0.749\t0.613\t0.705\t0.778\t0.816\t0.833\t0.775\n",
      "spath_top_1_2    \t0.755\t0.767\t0.629\t0.73 \t0.782\t0.805\t0.829\t0.784\n",
      "spath_top_1_1    \t0.775\t0.759\t0.623\t0.724\t0.78 \t0.82 \t0.829\t0.793\n",
      "spath_top_3_2    \t0.768\t0.762\t0.633\t0.73 \t0.767\t0.825\t0.825\t0.778\n",
      "w_spath_top_1_0  \t0.753\t0.744\t0.627\t0.732\t0.767\t0.806\t0.807\t0.775\n",
      "spath_top_3_0    \t0.757\t0.754\t0.632\t0.722\t0.762\t0.825\t0.824\t0.777\n",
      "w_spath_top_1_4  \t0.773\t0.752\t0.648\t0.757\t0.781\t0.81 \t0.826\t0.796\n",
      "spath_top_3_1    \t0.756\t0.749\t0.613\t0.704\t0.766\t0.812\t0.81 \t0.783\n",
      "spath_top_1_0    \t0.763\t0.738\t0.644\t0.691\t0.774\t0.808\t0.818\t0.782\n",
      "kc_2             \t0.709\t0.681\t0.618\t0.64 \t0.729\t0.777\t0.783\t0.725\n",
      "w_spath_top_1_2  \t0.776\t0.771\t0.621\t0.723\t0.78 \t0.833\t0.832\t0.791\n",
      "w_spath_top_3_4  \t0.762\t0.749\t0.628\t0.721\t0.774\t0.813\t0.832\t0.777\n",
      "kc_3             \t0.712\t0.697\t0.612\t0.623\t0.731\t0.78 \t0.786\t0.724\n",
      "tri_1            \t0.712\t0.695\t0.612\t0.651\t0.755\t0.782\t0.794\t0.726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grab all models\n",
    "mat = np.array(matrix)\n",
    "sortedArr = mat[mat[:,0].argsort()]\n",
    "# Print\n",
    "s = [[str(e) for e in row] for row in matrix]\n",
    "lens = [max(map(len, col)) for col in zip(*s)]\n",
    "fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "table = [fmt.format(*row) for row in s]\n",
    "print('\\n'.join(table))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column_Name      \tLRR  \tKNN  \tBNB  \tGNB  \tDCT  \tXGB  \tRMF  \tSVM  \n",
      "in_deg_0         \t0.704\t0.7  \t0.574\t0.617\t0.756\t0.795\t0.803\t0.725\n",
      "in_deg_1         \t0.719\t0.696\t0.61 \t0.632\t0.732\t0.803\t0.809\t0.729\n",
      "kc_0             \t0.705\t0.709\t0.619\t0.621\t0.738\t0.807\t0.814\t0.72 \n",
      "kc_1             \t0.707\t0.709\t0.605\t0.617\t0.749\t0.789\t0.819\t0.737\n",
      "kc_2             \t0.709\t0.681\t0.618\t0.64 \t0.729\t0.777\t0.783\t0.725\n",
      "kc_3             \t0.712\t0.697\t0.612\t0.623\t0.731\t0.78 \t0.786\t0.724\n",
      "out_deg_0        \t0.707\t0.704\t0.598\t0.619\t0.737\t0.78 \t0.803\t0.718\n",
      "out_deg_1        \t0.719\t0.714\t0.616\t0.65 \t0.73 \t0.796\t0.82 \t0.719\n",
      "pr_0             \t0.707\t0.706\t0.591\t0.63 \t0.76 \t0.817\t0.827\t0.735\n",
      "pr_1             \t0.71 \t0.694\t0.622\t0.633\t0.766\t0.823\t0.833\t0.719\n",
      "pr_2             \t0.716\t0.709\t0.593\t0.646\t0.774\t0.812\t0.827\t0.738\n",
      "pr_3             \t0.702\t0.681\t0.595\t0.635\t0.778\t0.814\t0.83 \t0.712\n",
      "spath_top_1_0    \t0.763\t0.738\t0.644\t0.691\t0.774\t0.808\t0.818\t0.782\n",
      "spath_top_1_1    \t0.775\t0.759\t0.623\t0.724\t0.78 \t0.82 \t0.829\t0.793\n",
      "spath_top_1_2    \t0.755\t0.767\t0.629\t0.73 \t0.782\t0.805\t0.829\t0.784\n",
      "spath_top_1_3    \t0.765\t0.736\t0.625\t0.709\t0.781\t0.809\t0.825\t0.771\n",
      "spath_top_1_4    \t0.767\t0.738\t0.613\t0.733\t0.772\t0.818\t0.814\t0.779\n",
      "spath_top_3_0    \t0.757\t0.754\t0.632\t0.722\t0.762\t0.825\t0.824\t0.777\n",
      "spath_top_3_1    \t0.756\t0.749\t0.613\t0.704\t0.766\t0.812\t0.81 \t0.783\n",
      "spath_top_3_2    \t0.768\t0.762\t0.633\t0.73 \t0.767\t0.825\t0.825\t0.778\n",
      "spath_top_3_3    \t0.763\t0.734\t0.62 \t0.699\t0.752\t0.801\t0.814\t0.772\n",
      "spath_top_3_4    \t0.761\t0.754\t0.63 \t0.706\t0.767\t0.812\t0.818\t0.774\n",
      "spath_top_min_1  \t0.758\t0.772\t0.613\t0.723\t0.766\t0.82 \t0.839\t0.781\n",
      "spath_top_min_3  \t0.757\t0.756\t0.605\t0.723\t0.777\t0.795\t0.815\t0.769\n",
      "tri_0            \t0.716\t0.721\t0.628\t0.639\t0.742\t0.797\t0.81 \t0.736\n",
      "tri_1            \t0.712\t0.695\t0.612\t0.651\t0.755\t0.782\t0.794\t0.726\n",
      "uuid             \t0.707\t0.711\t0.621\t0.605\t0.732\t0.791\t0.791\t0.727\n",
      "w_spath_top_1_0  \t0.753\t0.744\t0.627\t0.732\t0.767\t0.806\t0.807\t0.775\n",
      "w_spath_top_1_1  \t0.755\t0.749\t0.638\t0.728\t0.778\t0.827\t0.827\t0.779\n",
      "w_spath_top_1_2  \t0.776\t0.771\t0.621\t0.723\t0.78 \t0.833\t0.832\t0.791\n",
      "w_spath_top_1_3  \t0.76 \t0.748\t0.611\t0.69 \t0.769\t0.815\t0.818\t0.782\n",
      "w_spath_top_1_4  \t0.773\t0.752\t0.648\t0.757\t0.781\t0.81 \t0.826\t0.796\n",
      "w_spath_top_3_0  \t0.761\t0.748\t0.606\t0.723\t0.775\t0.81 \t0.818\t0.782\n",
      "w_spath_top_3_1  \t0.769\t0.743\t0.629\t0.707\t0.78 \t0.812\t0.824\t0.78 \n",
      "w_spath_top_3_2  \t0.764\t0.75 \t0.606\t0.704\t0.777\t0.812\t0.828\t0.782\n",
      "w_spath_top_3_3  \t0.771\t0.749\t0.613\t0.705\t0.778\t0.816\t0.833\t0.775\n",
      "w_spath_top_3_4  \t0.762\t0.749\t0.628\t0.721\t0.774\t0.813\t0.832\t0.777\n",
      "w_spath_top_min_1\t0.762\t0.741\t0.64 \t0.732\t0.775\t0.798\t0.826\t0.787\n",
      "w_spath_top_min_3\t0.764\t0.751\t0.629\t0.744\t0.762\t0.805\t0.833\t0.782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print\n",
    "s = [[str(e) for e in row] for row in sortedArr]\n",
    "lens = [max(map(len, col)) for col in zip(*s)]\n",
    "fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "table = [fmt.format(*row) for row in s]\n",
    "print('\\n'.join(table))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5_AM_Model_Pipeline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
